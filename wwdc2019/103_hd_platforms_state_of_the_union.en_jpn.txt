[ Music ]
[音楽]

>> Good afternoon, ladies and gentlemen.
 >>こんにちは、皆さん、こんにちは。

Please welcome Vice President of Software Sebastien Marineau-Mes.
 Software Sebastien Marineau-Mesの副社長を迎えてください。

[ Applause ]
 【拍手】

>> Good afternoon, everyone, and welcome to WWDC.
 >>こんにちは、皆さん、そしてWWDCへようこそ。

Did we love the morning keynote?
朝の基調講演が大好きでしたか。

[ Applause ]
 【拍手】

There you go.
そこに行きます。

[ Applause ]
 【拍手】

Now this year is one of our biggest for developers and we're really excited to show you what we've been working on and see what you think.
今年は開発者にとって最大の年の1つとなりました。現在取り組んでいることをお見せし、あなたの考えを見ていただけることをとても嬉しく思います。

This morning's keynote was just a taste of what's happening this year.
今朝の基調講演は、今年何が起こっているのかの単なる味です。

There is so much more that we want to share, and this afternoon we're going to focus on the areas that matter most to you as developers.
私たちが共有したいことはまだたくさんあります。今日の午後は、開発者としてあなたにとって最も重要な分野に焦点を当てます。

Are you ready to hear more?
もっと聞く準備ができていますか？

[ Applause ]
 【拍手】

There we go.
そこに行きます。

Now we've taken a huge step in terms of developer experience this year with the new SwiftUI framework as well as great interactive tools in Xcode.
今年は、新しいSwiftUIフレームワークとXcodeの優れたインタラクティブツールを使用して、今年の開発者エクスペリエンスの面で大きな一歩を踏み出しました。

And we've really seen each of our platforms get even deeper at what they do best.
そして私達は私達のプラットホームのそれぞれがそれらが最もよくすることでさらに深くなるのを本当に見ました。

We have powerful new pro capabilities for Mac, and new Dark Mode and rich updates -- sorry, independence for watchOS.
私たちは、Mac用の強力な新しいプロ機能、および新しいダークモードと豊富なアップデートを持っています - すみません、watchOSのための独立性。

On iOS, a new Dark Mode and great app updates.
 iOSでは、新しいダークモードと素晴らしいアプリのアップデート。

And finally, on iPadOS, a powerful operating system that now stands on its own.
そして最後に、iPadOSでは、今や自立している強力なオペレーティングシステムです。

Sorry, the monitors aren't working down here.
すみません、モニターはここで動作していません。

[ Laughter ]
 [ 笑い ]

There we go.
そこに行きます。

One of those is working, so I will go over to the left.
そのうちの1つが動作しているので、私は左に行きます。

Now these platforms represent a diverse range of devices and building great support for them is easy, thanks to a choice of many tools and APIs like AutoLayout, Size Classes and SwiftUI.
現在、これらのプラットフォームは多様なデバイスを表しており、AutoLayout、Size Classes、SwiftUIなどの多くのツールやAPIを選択することで、それらをサポートするのは簡単です。

So no more letterbox.
これ以上レターボックスはありません。

Your users get the best experience when your app works well on a wide range of device sizes.
アプリが幅広いデバイスサイズで正常に動作するとき、ユーザーは最高のエクスペリエンスを得られます。

And starting next spring, it will be an app store requirement to deliver UI that adapts to different screen sizes.
そして来春から、さまざまな画面サイズに適応するUIを提供することがアプリストアの要件になります。

Now tvOS is offering cool new capabilities -- [ Laughter ]
今tvOSはクールな新機能を提供しています -  [笑い]

[ Applause ]
 【拍手】

There we go.
そこに行きます。

[ Applause ]
 【拍手】

Now tvOS is offering cool new capabilities for developers this year, including multi-user support for third-party apps, new UI elements and options, SwiftUI and of course support for Xbox and PlayStation game controllers.
現在tvOSは、サードパーティのアプリケーションのマルチユーザーサポート、新しいUI要素とオプション、SwiftUI、そしてもちろんXboxとPlayStationのゲームコントローラのサポートを含む、今年開発者のための素晴らしい新機能を提供しています。

[ Applause ]
 【拍手】

Now this morning we announced an incredible new hardware platform with the new Mac Pro.
今朝、私たちは新しいMac Proを搭載した驚くべき新しいハードウェアプラットフォームを発表しました。

Do we love it?
好きですか？

[ Applause ]
 【拍手】

It is incredible, and it will really unlock amazing new kinds of apps.
それは信じられないことです、そしてそれは本当にアプリの驚くべき新しい種類のロックを解除します。

And we also built technologies that span all of our platforms, and we'll have a look at a few of these areas today, including accessibility, privacy, machine learning, Siri, augmented reality and finally Metal.
また、私たちはすべてのプラットフォームにまたがるテクノロジも構築しました。今日は、アクセシビリティ、プライバシー、機械学習、Siri、拡張現実、そして最後にMetalなど、これらの分野のいくつかを紹介します。

Now we want to focus on these three big areas this afternoon, and we're going to start with developer productivity.
それでは、今日の午後、これら3つの大きな分野に焦点を当てたいと思います。開発者の生産性から始めましょう。

Now everyone in this room knows that great tools can dramatically improve your productivity.
今すぐこの部屋の誰もが優れたツールが劇的にあなたの生産性を向上させることができることを知っています。

Great tools give you more time to be creative and they let you build better apps.
優れたツールを使用すると、クリエイティブになるまでの時間が長くなり、優れたアプリケーションを構築できます。

And the foundation of that experience is the programming language.
そしてその経験の基礎はプログラミング言語です。

Over the last five years, Swift has matured and is built into every Apple platform.
過去5年間で、Swiftは成熟し、あらゆるAppleプラットフォームに組み込まれてきました。

And Swift gives us the foundation for SwiftUI.
そしてSwiftはSwiftUIの基盤を私たちに提供します。

And Xcode is so much more than a code debugger -- sorry, code editor and debugger.
そしてXcodeはコードデバッガ以上のものです - 申し訳ありませんが、コードエディタそしてデバッガです。

It includes everything that you need to build an app, including support for continuous integration and testing.
継続的な統合とテストのサポートなど、アプリを構築するために必要なものがすべて含まれています。

And it gives you tools that let you explore new technologies such as machine learning and augmented reality.
そしてそれはあなたが機械学習や拡張現実感などの新しい技術を探求することを可能にするツールをあなたに与えます。

And finally, built on the strong foundation of our platforms, the SwiftUI framework will revolutionize how you build user interfaces.
そして最後に、私たちのプラットフォームの強力な基盤の上に構築されたSwiftUIフレームワークは、ユーザーインターフェースの構築方法に革命をもたらします。

And together, these three elements deliver a whole new level of productivity and they will fundamentally transform how all of you build apps.
そして、これら3つの要素が一体となってまったく新しいレベルの生産性を実現し、それらが根本的に、すべてのユーザーによるアプリの構築方法を変革します。

Now, are you ready to dive right into SwiftUI?
これで、SwiftUIに飛び込む準備はできましたか？

[ Applause ]
 【拍手】

Let's have Josh come up and tell us more.
それでは、Joshにお話を伺いましょう。

Josh?
ジョシュ？

[ Applause ]
 【拍手】

>> Thanks, Sebastien.
 >>ありがとう、Sebastien。

Okay, so SwiftUI, as you saw this morning, is a brand-new user interface framework built from the ground up in Swift for Swift.
さて、今朝見たようにSwiftUIはSwift for Swiftでゼロから構築されたまったく新しいユーザーインターフェースフレームワークです。

We designed it to let you write less code and have the code that you do write be better code, while letting you use more of that code across all Apple platforms.
私たちは、あなたがより少ないコードを書くことを可能にし、あなたが書くコードがより良いコードになるようにしながら、あなたがすべてのアップルプラットフォームにわたってあなたがそのコードのより多くを使うようにします。

Now first of all, there's so much functionality built into each individual line that you write that you're just going to write way less code.
まず第一に、あなたが書いた個々の行にはたくさんの機能が組み込まれているので、もっと少ないコードで書くことになります。

So let's take the app for choosing macOS release names that we looked at this morning, but without the animated transitions.
それでは、今朝見たmacOSリリース名を選ぶためのアプリを見てみましょう。ただし、アニメーション化された移行はありません。

If you've written an app with UIKit before, you know the types of pieces that you need in order to build this interface.
 UIKitを使って以前にアプリを書いたことがあれば、このインターフェースを構築するために必要な要素の種類はわかります。

It's not a lot of views, but there are many individual details that you need to get right.
それは多くの見解ではありませんが、正しく理解する必要がある個々の詳細がたくさんあります。

With SwiftUI, it is way less code.
 SwiftUIでは、それははるかに少ないコードです。

Fewer than 20 lines focused on just three key things.
たった3つの重要なことに焦点を絞った20行未満。

First, a few lines to define the structure and layout of your views.
まず、ビューの構造とレイアウトを定義するための数行です。

Then some image and text views to display your content.
それからあなたのコンテンツを表示するためのいくつかの画像とテキストビュー。

And finally, parameters and modifiers to adjust how it all looks.
そして最後に、それがすべてどのように見えるかを調整するためのパラメータと修飾子。

Now let' stake a look a little bit more closely at just a few of these lines.
それでは、これらのうちのいくつかの行をもう少し詳しく見てみましょう。

The scrolling list itself is barely any code at all.
スクローリングリスト自体は、ほとんどコードです。

You just declare the list and then describe the model objects to be used in each row.
リストを宣言してから、各行で使用されるモデルオブジェクトを記述するだけです。

There's no setup, there's no configuration and there's no callbacks.
セットアップも設定も、コールバックもありません。

Now the image at the top is just as simple.
今すぐ上部の画像も同じくらい簡単です。

You display an image, clip it to a circle and add a shadow.
画像を表示し、それを円に切り取り、影を付けます。

And it's not just less code.
そしてそれは単なるコードではありません。

It's better code.
それはより良いコードです。

We designed the API to make the obvious approach be the right approach.
明白なアプローチが正しいアプローチになるようにAPIを設計しました。

The right way to create this label is exactly the one line of code that you would think to write.
このラベルを作成するための正しい方法は、あなたが書くと思う1行のコードです。

It supports dynamic type, Dark Mode and more.
ダイナミックタイプ、ダークモードなどをサポートしています。

In fact, even the string interpolation used here is fully localizable.
実際、ここで使用されている文字列補間でも完全にローカライズ可能です。

This simplicity eliminates entire categories of errors.
この単純さはエラーの全カテゴリーを排除します。

Looking at our list again, its rows update automatically if the model changes, ensuring that your UI is always up to date and never displaying out-of-date data.
もう一度リストを見ると、モデルが変更されるとその行が自動的に更新されるため、UIは常に最新の状態に保たれ、古くなったデータは表示されません。

And it's easy to read too.
そしてそれも読みやすいです。

The code for this image with a corner radius of three says exactly that.
この画像のコーナ半径が3のコードは、正確にそれを示しています。

Reading SwiftUI is like having someone explain that interface to you.
 SwiftUIを読むことは、誰かがあなたにそのインターフェースを説明するようなものです。

And SwiftUi's code is available everywhere, helping you reuse more of your code across all Apple platforms.
そして、SwiftUiのコードは至るところで利用可能であり、あなたがあなたがもっと多くのコードを全てのAppleプラットフォームの間で再利用するのを助けます。

Now you've long been able to share your model and low-level drawing and compositing code, but higher-level UI code has remained mostly platform-specific.
これで、モデルと低レベルの描画コードおよび合成コードを長い間共有できましたが、高レベルのUIコードはほとんどプラットフォーム固有のままです。

With SwiftUI, we're raising that bar, enabling you to share far more.
 SwiftUIを使用すると、その水準を引き上げることで、より多くの情報を共有できるようになります。

Now of course you're still going to want to tailor your interfaces for each individual platform to ensure that your app feels great everywhere that you deploy it.
もちろん、アプリケーションを配置した場所のどこにでも快適に表示できるように、個々のプラットフォームに合わせてインターフェイスを調整する必要があります。

But with SwiftUI's common set of API patterns, you can learn those tools once and then apply them everywhere, getting you a native interface on each platform you deploy to.
しかし、SwiftUIの共通APIパターンセットを使用すれば、これらのツールを一度習得してからどこにでも適用することができ、デプロイするプラットフォームごとにネイティブインターフェイスが得られます。

SwiftUI is designed with a strong set of four core principles.
 SwiftUIは強力な4つのコア原則のセットで設計されています。

First, a declarative syntax shifts UI programming away from how to update the screen and instead lets you just focus on what you want to display.
まず、宣言的な構文により、UIプログラミングを画面の更新方法から切り離し、代わりに表示したいものに集中することができます。

For example, let's say that you want to build a label with a headline font and a gray color.
たとえば、見出しのフォントとグレーの色でラベルを作成したいとしましょう。

Describing how to get that is a multi-step process with many steps having to happen in a specific order.
それをどのように実現するかを記述することは、多くのステップが特定の順序で行われなければならないマルチステッププロセスです。

But describing what you want requires no translation.
しかし、あなたが欲しいものを記述することは翻訳を必要としません。

Text that says Done with a font for a headline that's colored gray.
灰色の見出しのフォントでDoneと書かれているテキスト。

SwiftUI lets you say exactly that with a great new declarative syntax.
 SwiftUIを使用すると、新しい宣言的構文を使用して、そのことを正確に言えます。

And it's the minimum code necessary to describe exactly your idea.
そしてそれはあなたの考えを正確に記述するのに必要な最小限のコードです。

And iteration becomes significantly faster as well.
そして、繰り返しもかなり速くなります。

If you later need to change that label to become a button, that's a one-line change.
後でそのラベルを変更してボタンにする必要がある場合、それは1行の変更です。

[ Applause ]
 【拍手】

I know, it's pretty great.
私は知っています、それはかなり素晴らしいです。

[ Applause ]
 【拍手】

All right, so our second principle is that we should provide automatic functionality whenever it's possible.
大丈夫です、だから私たちの2番目の原則は可能な限り自動機能を提供するべきだということです。

This eliminates the need for a huge amount of code that you used to have to write by hand.
これにより、これまで手作業で記述しなければならなかった大量のコードが不要になります。

Our app for naming macOS releases is pretty simple, yet it does include a huge amount of automatic functionality.
 macOSリリースの命名のための私たちのアプリはとても単純です、それでもそれは自動機能の膨大な量を含みます。

We get default handling of spacing and safe area insets.
スペースとセーフエリアインセットのデフォルトの処理が行われます。

Localizability and layout adjustments for right-to-left languages.
右から左へ記述する言語のローカライズ性とレイアウトの調整

Dynamic type, Dark Mode and so much more, all from that one minimal description.
動的型、ダークモード、その他さまざまなことが、すべて1つの最小限の説明から可能です。

It's an incredible amount of automatic functionality for a small amount of code, but there is one more thing that is just so important that it really deserves special attention.
これは、少量のコードに対して驚くべき量の自動機能ですが、非常に重要な点がもう1つあります。

Our modern interfaces are interactive and they're animated.
私たちの最新のインターフェースはインタラクティブで、それらはアニメーション化されています。

And with SwiftUI, that same interface declaration is also automatically fully animatable.
そしてSwiftUIでは、同じインターフェース宣言も自動的に完全にアニメート可能になります。

Animations can be enabled for the entire hierarchy with just one line of code.
 1行のコードでアニメーションを階層全体で有効にできます。

There's no bookkeeping, there's no preparation and there's never any cleanup.
簿記はありません、準備はありませんし、クリーンアップもありません。

If you've used Keynote Magic Move animations before, SwiftUI animations are that easy and even more powerful.
 Keynote Magic Moveアニメーションを以前に使用したことがあれば、SwiftUIアニメーションはそれほど簡単で強力です。

And for views that are added and removed, you can specify how they transition in and out with just one more line of code.
また、追加および削除されたビューについては、あと1行のコードでビューの内外への遷移方法を指定できます。

While animations are in progress, your app remains fully interactive and responsive and ready to handle user input at any time.
アニメーションが進行中でも、アプリは完全にインタラクティブで反応がよく、いつでもユーザー入力を処理する準備ができています。

And if the user ever interrupts one of those animations or if you need to move to a new location, SwiftUI handles all of that automatically too.
また、ユーザーがこれらのアニメーションの1つを中断した場合や、新しい場所に移動する必要がある場合は、SwiftUIがそのすべてを自動的に処理します。

Now our third principle is that compositional APIs are easier to learn and let you iterate a lot faster.
私たちの3番目の原則は、合成APIの方が習得が簡単で、反復処理がはるかに速いということです。

We've looked at how we can declare an individual view like this text label.
このテキストラベルのように個々のビューをどのように宣言できるかを見てきました。

But declaring more complex views is just as easy.
しかし、より複雑なビューを宣言するのも同じくらい簡単です。

You just compose together multiple smaller pieces.
あなたはただ複数の小さい部分を一緒に構成します。

Containers like horizontal and vertical stacks let you easily build powerful layouts by just combining together multiple simple pieces.
水平および垂直スタックなどのコンテナを使用すると、複数の単純な要素を組み合わせるだけで、強力なレイアウトを簡単に構築できます。

And SwiftUI applies composition to view properties as well, using a standard modifier syntax.
また、SwiftUIは標準の修飾子構文を使用して、ビュープロパティにも合成を適用します。

A common set of modifiers can be applied to any view, like color applied here to make this text gray.
このテキストをグレーにするためにここで適用される色のように、一般的な修飾子のセットを任意のビューに適用できます。

This compositional approach lets you learn a small set of views and modifiers and then combine them together to create progressively more powerful interfaces.
この構成アプローチでは、少数のビューと修飾子を学び、それらを組み合わせて次第に強力なインターフェースを作成することができます。

And our final principle is that your interface should always be in a consistent state.
そして私たちの最後の原則は、あなたのインターフェースは常に一貫した状態にあるべきだということです。

Your UI is a reflection of your app's data, so the two should always be in synch at all times.
あなたのUIはあなたのアプリのデータを反映しているので、2つは常に同期しているべきです。

With traditional APIs, this can be error-prone.
従来のAPIでは、これは間違いを起こしやすいものです。

But with SwiftUI, your interface updates automatically any time the data changes.
しかしSwiftUIでは、データが変更されるたびにインターフェースが自動的に更新されます。

Now there are two common places that your data might likely come from.
今すぐあなたのデータが由来する可能性がある2つの一般的な場所があります。

Now the first are your model objects.
今すぐ最初のモデルオブジェクトです。

And you can use your existing model objects directly by simply conforming them to a new bindable object protocol.
また、既存のモデルオブジェクトを新しいバインド可能なオブジェクトプロトコルに準拠させるだけで直接使用できます。

Its only requirement is that you specify when the data in your model changes.
唯一の要件は、モデル内のデータがいつ変更されるかを指定することです。

Now the second place is temporary UI state, like whether the view is currently in editing mode.
 2番目の場所は、ビューが現在編集モードになっているかどうかなど、一時的なUI状態です。

These are declared using a simple state wrapper applied to any property on your view.
これらは、ビュー上の任意のプロパティに適用された単純な状態ラッパーを使用して宣言されています。

We're all used to every property on every view being mutable, but once you start using SwiftUI, you're going to be shocked to realize how little mutable state your app actually needs.
私たちはみんなすべてのビューのすべてのプロパティが変更可能であることに慣れていますが、SwiftUIを使い始めると、アプリが実際に必要な変更可能ステートがほとんどないことに気付くことになります。

Now whenever your model or state changes, that UI is going to update automatically.
モデルや状態が変わるたびに、そのUIは自動的に更新されます。

And because it's all Swift code, you get this behavior while still being able to use your model objects directly within that interface declaration.
そしてそれは全てSwiftコードなので、そのインターフェース宣言の中であなたのモデルオブジェクトを直接使用することができる一方であなたはこの挙動を得ます。

You can even transform and format values in line with no additional indirection needed.
追加の間接参照を必要とせずに、値を変換してインラインでフォーマットすることもできます。

For example, this string interpolation can be used to format a date, resulting in fully localized formatted text.
たとえば、この文字列補間を使って日付をフォーマットすると、完全にローカライズされたフォーマット済みテキストになります。

All of this means that with Swift UI, you're going to write less code and get a more consistent UI.
これらすべてのことは、Swift UIを使用することで、作成するコードが少なくなり、より一貫性のあるUIが得られることを意味します。

Those are the four core principles of SwiftUI.
これらがSwiftUIの4つのコア原則です。

A powerful declarative syntax enabling a huge amount of automatic functionality with a compositional API that ensures your interface is always in a consistent state.
あなたのインターフェースが常に一貫した状態にあることを保証するコンポジションAPIを使って膨大な量の自動機能を可能にする強力な宣言的シンタックス。

And a great new framework deserves incredible tools.
そして素晴らしい新しいフレームワークは信じられないほどのツールに値します。

And we've created a whole brand-new workflow within Xcode designed from the ground up for SwiftUI.
また、SwiftUI用にゼロから設計されたまったく新しいワークフローをXcode内に作成しました。

You get the power and flexibility of code combined with the ease of use and rapid iteration of a UI tool.
あなたは、UIツールの使いやすさと迅速な反復と組み合わせたコードのパワーと柔軟性を手に入れます。

You always have access to both at all times, so you'll never have to choose between them again.
あなたはいつも両方にアクセスすることができますので、二度と選ぶ必要はありません。

And because the tools work on your actual existing source code, you have a truly live development experience.
そしてツールはあなたの実際の既存のソースコード上で動作するので、あなたは本当にライブ開発の経験をします。

Now to really understand how amazing this workflow is, you just need to see it again live.
このワークフローの素晴らしさを本当に理解するためには、もう一度このワークフローを実行する必要があります。

And to show it to you now, I'll invite Kevin up to give you a demo.
そして今すぐあなたにそれを見せるために、私はあなたにデモをするためにケビンを招きます。

[ Applause ]
 【拍手】

>> Thanks, Josh.
 >>ありがとう、ジョシュ。

You guys ready to have some fun?
あなたは楽しい時を過す準備ができていますか？

All right, so I'm building a hiking app and I want to add a view to my table view cell that tells me how difficult a trail is.
大丈夫です、だから私はハイキングアプリを作っています、そして私はトレイルがどれほど難しいかを教えてくれる私のテーブルビューセルにビューを追加したいです。

So we're going to start in the library.
それでは、図書館から始めましょう。

We're going to have some text.
テキストをいくつか用意します。

And as I'm dragging, Xcode is suggesting layouts for me.
ドラッグしているうちに、Xcodeは私にレイアウトを提案しています。

Now I just tell Xcode where I want it and Xcode figures out the layout for me.
今、私はそれを欲しいところにXcodeに伝えるだけで、Xcodeは私のためにレイアウトを考え出します。

And now we can edit the properties of this view.
これで、このビューのプロパティを編集できます。

So I'm just going to command click in the canvas here and get custom-tailored inspectors right here.
そこで、ここでキャンバス内をクリックして、ここにカスタムメイドのインスペクタを作成します。

Let's make this text a little bit smaller.
このテキストをもう少し小さくしましょう。

Now watch -- watch the code while I do this.
今すぐ見る - これをしている間にコードを見てください。

You'll see it writes the code for me.
あなたはそれが私のためにコードを書いているのを見るでしょう。

Now, we can do the same thing over here in the source editor by just editing the code.
これで、コードを編集するだけで、ソースエディタでここでも同じことができます。

And you can see Xcode builds and runs my code and updates the canvas on the right.
そして、Xcodeが私のコードを構築して実行し、右側のキャンバスを更新するのを見ることができます。

Now no matter where I'm working, I get access to all of my design tools.
今どこにいても、自分のデザインツールすべてにアクセスできます。

So I'm just going to command click on this V stack, going to open up the inspectors.
それで、私はちょうどこのVスタックをクリックしてインスペクタを開くつもりです。

And again I can just modify the properties that I want.
また、必要なプロパティを変更することもできます。

It's just so fast to iterate.
繰り返すのはとても速いです。

Now, you might notice that this view has a couple inputs like this title and this difficulty.
さて、あなたはこのビューにこのタイトルとこの難しさのようないくつかの入力があることに気づくかもしれません。

So how does Xcode know what data to show in the preview?
では、Xcodeはどのようにしてプレビューに表示するデータを知るのでしょうか。

This has always been one of the challenges with UI development: what data do we show during design time?
これは常にUI開発における課題の1つでした。設計時にどのようなデータを表示しますか？

And this is why we invented Xcode previews.
これが、Xcodeのプレビューを発明した理由です。

What is a preview?
プレビューとは何ですか？

I'll show you.
お見せします。

So let me scroll down here.
それではここで下にスクロールさせてください。

This snippet of code here -- a preview is just a snippet of code in my application that configures it for design time.
このコードスニペットはここにあります - プレビューはデザインタイムのためにそれを構成する私のアプリケーションのコードのスニペットです。

Because it's in my application, I get access to all the code in my project.
これは私のアプリケーション内にあるので、私は自分のプロジェクト内のすべてのコードにアクセスできます。

And because it's in my project, I can check it in and share it with my team members.
それは私のプロジェクトにあるので、チェックインしてチームメンバーと共有することができます。

And it's so easy to try different data.
そして別のデータを試すのはとても簡単です。

Now actually here Half Dome is pretty hard.
今ここで実際にここでハーフドームはかなり難しいです。

So let's see what it looks like at hard.
それでは、それが一見ハードに見えるものを見てみましょう。

And that's because it's 16 miles, not 6.
それは6マイルではなく16マイルだからです。

And that's really compiling code.
そしてそれは本当にコンパイルコードです。

Now because this is SwiftUI code, I get access to all the modifiers that I would use for the rest of my UI development.
これがSwiftUIコードなので、私は私の残りのUI開発に使用するすべての修飾子にアクセスできます。

So we can see what it looks like in Dark Mode.
だから我々はそれがダークモードでどのように見えるかを見ることができます。

And I also have preview-specific modifiers as well.
また、プレビュー固有の修飾子もあります。

So by default previews are the size of a device, but since we're working on a table view cell, let's just focus in on that content.
そのため、デフォルトではプレビューはデバイスのサイズになりますが、テーブルビューのセルに取り組んでいるので、そのコンテンツに注目しましょう。

So I'll just make that the size that fits.
だから私はちょうどそれが合うサイズにするつもりです。

Okay, now here is the really cool thing about previews.
さて、今ここでプレビューについて本当にクールなことです。

You can have as many as you want.
あなたは好きなだけ持つことができます。

So let's add a second preview with completely different data.
それでは、まったく異なるデータを含む2番目のプレビューを追加しましょう。

But let's not stop there.
しかし、それだけではありません。

Let's command click, repeat it a couple of times.
クリックを命令しましょう、それを数回繰り返してください。

Let's enumerate over some common dynamic type sizes and then let's configure our cell to use that dynamic type size.
一般的な動的型サイズをいくつか列挙してから、その動的型サイズを使用するようにセルを構成しましょう。

And there at a glance I can see my cell with light mode, Dark Mode, multiple different dynamic type sizes all at the same time.
一目で、ライトモード、ダークモード、複数の異なるダイナミックタイプサイズのセルを同時に見ることができます。

[ Applause ]
 【拍手】

Now when I tap on this cell, I want to go to a detailed view.
このセルをタップすると、詳細ビ​​ューに行きたいのです。

So let's switch over to that file now and take a look.
それでは、今そのファイルに切り替えて見てみましょう。

Now I've learned through the years of hiking that you should never judge a trail by its name.
今、私は何年ものハイキングを通して、トレイルをその名前で判断するべきではないことを学びました。

So it's really important to me that we can configure our detail view to make that image really large.
だから私は私たちがその画像を本当に大きくするために私たちの詳細ビューを設定できることが本当に重要です。

And I've already done that with some SwiftUI state here.
そして私はすでにSwiftUIの状態でこれを行っています。

So when we tap the banner, we want to toggle that expansion state.
そのため、バナーをタップすると、その展開状態を切り替える必要があります。

Now I can test that right here in the UI just by clicking this play button.
これで、再生ボタンをクリックするだけで、UIでそのことをテストできます。

This takes any preview that I have and makes it fully interactive.
これは私が持っているすべてのプレビューを取り、それを完全にインタラクティブにします。

So I can just click and test out those different expansion states.
それで私はただクリックしてそれらの異なる展開状態をテストすることができます。

Now we can really polish this up with an animation.
これで、アニメーションでこれを本当に磨くことができます。

It's so easy.
それはとても簡単です。

So I can just wrap my state change in a whip animation block, and now I get a beautiful default animation.
そのため、状態の変化をホイップアニメーションブロックでラップするだけで、美しいデフォルトのアニメーションが得られます。

[ Applause ]
 【拍手】

And it's just as easy to customize that.
それをカスタマイズするのも同じくらい簡単です。

So let's slow it down for some dramatic effect, and now I get a beautiful animation opening it up.
それでは、いくつかの劇的な効果のためにそれを遅くしましょう、そして今私はそれを開く美しいアニメーションを手に入れます。

Now what's so cool about SwiftUI is that every animation is cancellable and reversible, leaving my application responsive the whole time.
 SwiftUIの素晴らしいところは、すべてのアニメーションがキャンセル可能でリバーシブルになっていることです。これにより、私のアプリケーションはずっと応答しやすくなります。

Okay, so we have a table view cell and we have a detail view.
さて、テーブルビューのセルがあり、詳細ビューがあります。

So let's put it all together.
それでは、まとめてみましょう。

So I'm going to switch over to my last value here, which has a bunch of different trails and a list.
だから私はここで私の最後の値に切り替えていくつもりです。

So what I want to do is I actually want to see what this looks like on a real device.
だから私がやりたいことは、実際にこれが実際のデバイスでどのように見えるかを見たいということです。

So with the click of a button -- let's click this -- Xcode is going to build my project for the device.
ボタンをクリックするだけで - これをクリックしましょう -  Xcodeはデバイス用に私のプロジェクトをビルドします。

It's going to install it and it's going to launch my preview right here on the device.
それはそれをインストールしようとしています、そしてそれは私のプレビューをデバイス上でまさにここで起動するつもりです。

And you can see it's fully interactive right here.
そして、あなたはそれがここで完全にインタラクティブであることを見ることができます。

So first let's use that cell that we built.
それでは最初に、作成したセルを使用しましょう。

So I'll just change this text to be a trail cell.
だから私はただこのテキストをトレイルセルに変更します。

Now you can see we're seeing our trails show up there.
これで、トレイルが表示されているのがわかります。

And now when I tap on this, I want it to go to our detail view that we built.
そして今、これをタップすると、作成した詳細ビューに移動したいのです。

This is so easy with SwiftUI.
これはSwiftUIではとても簡単です。

It's just going to wrap this in a navigation button, and that tells us to go to our detailed view.
これをナビゲーションボタンで囲むだけで、詳細ビューに進むことができます。

And now you can see the chevron shows up.
そして今、あなたはシェブロンが現れるのを見ることができます。

So let's check out Snow Creek and let's move in on that picture.
それでは、Snow Creekをチェックして、その絵に移りましょう。

And okay, snowy and difficult.
そして、大丈夫、雪の中、そして難しい。

That does not sound like a fun trail.
それは楽しい道のようには思えません。

So what I'm going to do with just one line of SwiftUI code is add swipe to delete.
だから私はSwiftUIコードの1行だけでやろうとしている削除するスワイプを追加します。

And now we can say, "We don't want to do that trail." And now lastly, let's see what it looks like in Dark Mode.
そして今、私たちは「私たちはその道をやりたくない」と言うことができます。 そして最後に、ダークモードの様子を見てみましょう。

Without any work, it's going to put my preview in Dark Mode and you can see it looks beautiful.
何もしなければ、プレビューはダークモードになり、きれいに見えることがわかります。

[ Applause ]
 【拍手】

We can tap on our valley floor, zoom in.
私たちは谷間の床をタップしてズームインできます。

And that looks like a great way to end the week.
そしてそれは週を終わらせるための素晴らしい方法のように見えます。

So we just built an app with navigation, dynamic type size, light mode, Dark Mode, multiple different data and saw on the real device all without ever building and running.
そのため、ナビゲーション、ダイナミックタイプサイズ、ライトモード、ダークモード、複数の異なるデータを使用してアプリを作成し、実際のデバイス上ですべて構築して実行することなく確認しました。

Now that's fun.
今それは楽しいです。

All right, Josh, back to you.
ジョシュさん、よろしくお願いします。

[ Applause ]
 【拍手】

>> Thanks, Kevin.
 >>ありがとう、ケビン。

All right, this is really an incredible new workflow for fully native code.
すべての権利、これは本当に完全にネイティブコードのための本当に信じられないほど新しいワークフローです。

What you do in the tool is always debuggable, diffable, searchable, and understandable.
ツールであなたがすることは常にデバッグ可能、拡散可能、検索可能、そして理解可能です。

And because you can always edit the code directly, you get incredible flexibility in your workflow.
そして、あなたはいつでもコードを直接編集することができるので、あなたはあなたのワークフローにおいて信じられないほどの柔軟性を得ます。

And SwiftUI is deeply integrated in all of our operating systems, so using it results in a fully native app for whichever platforms you target.
そしてSwiftUIは私たちのすべてのオペレーティングシステムに深く統合されているので、それを使うことであなたがターゲットにしているプラ​​ットフォームのための完全にネイティブなアプリになるでしょう。

You get the same performance, the same behavior and the same controls as any other native app.
他のネイティブアプリと同じパフォーマンス、同じ動作、同じコントロールが得られます。

And you can adopt SwiftUI at your own pace.
そして、あなたは自分のペースでSwiftUIを採用することができます。

You can use it for anything, from just one view in your app all the way up to the entire application.
あなたは、あなたのアプリケーションの一つのビューからアプリケーション全体に至るまで、あなたは何にでもそれを使うことができます。

It works seamlessly with all of your existing UIKit, AppKit and WatchKit code so you don't need to rewrite anything.
既存のすべてのUIKit、AppKit、およびWatchKitコードとシームレスに連携するので、何も書き直す必要はありません。

And to get you up to speed quickly, our documentation team has developed a brand-new style of interactive documentation.
また、迅速に対応できるように、Googleのドキュメントチームは、まったく新しいスタイルのインタラクティブドキュメントを開発しました。

It quickly takes you step-by-step from creating a new project all the way up to building a fully interactive interface.
新しいプロジェクトの作成から完全にインタラクティブなインターフェースの構築に至るまで、すばやくステップバイステップで移動できます。

So you'll be up to speed in no time.
だから、あなたはすぐにスピードに慣れるでしょう。

[ Applause ]
 【拍手】

So that's SwiftUI and some of the new tools in Xcode.
それがSwiftUIとXcodeの新しいツールの一部です。

Of course, this is a huge year for Swift and Xcode, so there's even more to this story.
もちろん、これはSwiftとXcodeにとって大きな年なので、この話にはまだまだあります。

And to tell you more about it, I'll hand things off to Matthew.
そしてそれについてあなたにもっと話すために、私は物事をマシューに手渡すつもりです。

Thanks.
ありがとう。

[ Applause ]
 【拍手】

>> Thank you, Josh.
 >>ありがとう、ジョシュ。

Our tools released this year bring together innovations in Swift and Xcode to deliver some awesome results.
今年リリースされた当社のツールは、SwiftとXcodeの革新的技術を組み合わせて素晴らしい結果をもたらします。

So let's start with Swift.
それではSwiftから始めましょう。

Now in our fifth year, Swift has matured and is continuing to leap forward.
今、私たちの5年目で、Swiftは成熟し、飛躍し続けています。

Where our newest and flagship technologies, from machine learning to augmented reality are possible only because of Swift and it now being part of our OS.
機械学習から拡張現実まで、私たちの最新かつ重要なテクノロジが可能なのは、Swiftとそれが今や私たちのOSの一部になっているからです。

To achieve this, earlier this spring we introduced ABI stability which reduces the size of your apps by using a single shared Swift runtime.
これを実現するために、今春初めに単一の共有Swiftランタイムを使用することでアプリのサイズを縮小するABI安定性を導入しました。

[ Applause ]
 【拍手】

And we are following that up today with module stability which ensures compatibility -- yes.
互換性を保証するモジュールの安定性を追求しています - はい。

[ Applause ]
 【拍手】

This completes the picture by ensuring compatibility for your binaries with the current and future versions of the Swift compiler.
これにより、バイナリと現在および将来のSwiftコンパイラのバージョンとの互換性が保証されます。

And these come alongside a number of other language features, tools editions and performance and code size improvements, all which further extend the potential Swift brings to your projects.
そしてこれらは、Swiftがあなたのプロジェクトにもたらす可能性をさらに広げる、他の多くの言語機能、ツールのエディション、そしてパフォーマンスとコードサイズの改善と並んでいます。

So Swift is already the language for your apps and now more than ever for common code to share across all Apple platforms.
そのため、Swiftはすでにあなたのアプリの言語であり、今やこれまで以上に共通のコードをすべてのAppleプラットフォームで共有するための言語となっています。

In fact, sharing is the reason we created Swift Packages which are the best way to develop and share your own code and reuse code from others.
実際、共有がSwiftパッケージを作成した理由です。これは、自分のコードを開発および共有し、他のコードを再利用するための最良の方法です。

And today we have two big announcements.
そして今日は2つの大きな発表があります。

GitHub will be adding support for Swift packages to the GitHub Package Registry.
 GitHubはSwitパッケージのサポートをGitHubパッケージレジストリに追加する予定です。

[ Applause ]
 【拍手】

Which is perfect because Xcode now seamlessly supports Swift packages for apps on iOS, iPadOS and all of our platforms.
 XcodeがiOS、iPadOS、およびすべてのプラットフォーム上のアプリケーション用のSwiftパッケージをシームレスにサポートするようになったため、これは完璧です。

[ Applause ]
 【拍手】

Swift packages are top-level items in your workspaces, always visible, always accessible, and deeply integrated.
 Swiftパッケージは、ワークスペース内の最上位項目であり、常に表示され、常にアクセス可能で、そして高度に統合されています。

Packages from the community and those packages you create get instant access to all of Xcode's work flows for source control, debugging, testing, the works.
コミュニティのパッケージとあなたが作成したパッケージは、ソース管理、デバッグ、テスト、そして作業のためにXcodeのすべてのワークフローに即座にアクセスすることができます。

So Swift packages built into Xcode, it's sharing code the way you've always wanted.
 SwiftパッケージはXcodeに組み込まれているので、コードを共有しています。

Now that's just the start of our Xcode release this year, which is focused on maximizing your productivity.
これが今年のXcodeリリースのほんの始まりに過ぎません。それはあなたの生産性を最大にすることに焦点を合わせています。

And we have a number of improvements today to share with you as we take Xcode up to 11.
また、Xcodeを11まで引き上げると、今日あなたと共有するための改善点がいくつかあります。

So let's get started with one of our biggest changes which is the Xcode Workspace.
それでは、Xcode Workspaceという最も大きな変更点の1つから始めましょう。

We are giving you full editorial control.
私たちはあなたに完全な編集管理を与えています。

You can now create and manage editors however you like.
あなたは今、あなたが好きなエディタを作成し管理することができます。

Whatever your preferred style and layout is, you can simply add and remove editors whenever and wherever you see fit.
好みのスタイルやレイアウトが何であれ、いつでもどこでも好きなときにエディタを追加したり削除したりできます。

[ Applause ]
 【拍手】

And even better, your workspaces can now focus too.
さらに良いことに、あなたのワークスペースは今も焦点を合わせることができます。

So you can take any editor and maximize it, and then when you're done, just put it back and it will go right back to where you started.
それで、あなたはどんなエディタでもそれを最大化することができます、そして、それが終わったら、ただそれを元に戻すだけでそれはあなたが始めたところに戻ります。

[ Applause ]
 【拍手】

So whether you're working on the smallest of laptops or with the largest of displays, your workspace now works for you.
それで、あなたが最小のラップトップで作業しているか最大のディスプレイで作業しているかにかかわらず、あなたのワークスペースはあなたのために今働く。

Now the related content in our editors, the smart selections like counterparts, are also getting a huge boost.
現在、私たちのエディターの関連コンテンツ、カウンターパートのようなスマートセレクションもまた、大きな後押しを受けています。

There are new options like previews, canvas, live views and more.
プレビュー、キャンバス、ライブビューなどの新しいオプションがあります。

You can use the related content in any editor in your workspace.
ワークスペースのどのエディタでも関連コンテンツを使用できます。

And you'll like this one best of all.
そして、あなたは何よりもこれが一番好きです。

When there is no content, they automatically disappear so you no longer need to manager their visibility.
コンテンツがなくなると、コンテンツは自動的に消えます。そのため、あなたはもはやそれらの可視性を管理する必要はありません。

[ Applause ]
 【拍手】

Now once you get your workspace set up, it's all about the editing, and I'd like to show you a quick demonstration of some of the new source editing features we have for you this year.
ワークスペースをセットアップした後は、編集作業がすべて終了しました。今年度の新しいソース編集機能のいくつかについて簡単に説明します。

To help you configure each editor the way you like, there's a new Options menu in the upper right.
各エディタを好きなように設定できるように、右上に新しい[オプション]メニューがあります。

You can see here I can enable the assistants or any of the related content.
あなたはここで私がアシスタントまたは任意の関連コンテンツを有効にすることができるのを見ることができます。

I could turn on code coverage or source control authors.
コードカバレッジやソース管理の作成者をオンにすることができます。

I'm going to turn on our newest feature, Mini map.
私たちの最新機能であるミニマップをオンにします。

So the mini map gives you a structural overview of your file to help you navigate.
だからミニマップはあなたがあなたがナビゲートするのを助けるためにあなたにあなたのファイルの構造的な概観を与える。

You can see documentations, method and functions.
あなたはドキュメンテーション、方法と機能を見ることができます。

It makes it really easy to move about the file.
ファイルを簡単に移動できます。

If you'd like to leave yourself some other landmarks, you can use the mark syntax to add labels and horizontal dividers that show up in your source and in the mini map.
他のランドマークを残したい場合は、markシンタックスを使用して、ソースとミニマップに表示されるラベルと水平方向の仕切りを追加できます。

[ Applause ]
 【拍手】

Now if I hover over the mini map, you'll see the symbolic landmarks for the file.
ミニマップにカーソルを合わせると、ファイルの象徴的なランドマークが表示されます。

Here's a pro tip: hold down the command key and you'll see all of the landmarks for the file to make it really easy to navigate to exactly where you want to go.
ここにプロのヒントがあります。コマンドキーを押したままにすると、ファイルのすべてのランドマークが表示され、目的の場所に簡単に移動できるようになります。

[ Applause ]
 【拍手】

And the mini map will show you issues, test failures, even in-file find results.
また、ミニマップには問題、テストの失敗、ファイル内の検索結果も表示されます。

And we've made it fully accessible.
そして私達はそれを完全にアクセス可能にしました。

You'll find our source editor now pops and your code is more vivid as we've deepened our syntax coloring.
あなたは私たちのソースエディタが今飛び出るのを見つけるでしょう、そして私達が私達の構文のカラーリングを深めたのであなたのコードはもっと鮮やかです。

You'll also see that we've increased our documentation support here with italics, bold and code voice in the documentation.
また、ここではイタリック体、太字、コード内の音声を使用して、ドキュメントのサポートが強化されています。

You'll also see that when you add documentation, it automatically adds in missing parameters that you may have added after you typed your documentation.
また、ドキュメントを追加すると、ドキュメントを入力した後に追加された可能性のある不足しているパラメータが自動的に追加されます。

[ Applause ]
 【拍手】

And what's even better is to help you keep your documentation and code in synch.
さらに優れているのは、ドキュメントとコードを同期させることです。

You'll find Edit All and Scope now changes both, all at the same time.
 [すべて編集]と[スコープ]が両方同時に変更されていることがわかります。

[ Applause ]
 【拍手】

Now we also wanted to add some additional help to help you keep track of your changes.
今、私たちはまたあなたがあなたの変更を追跡するのを助けるためにいくつかの追加の助けを加えたいと思いました。

If I'd like to review all of the changes for this file, I can open up the new Source Control History Inspector which shows me all the changes that have been made to this file, and I can quickly jump to any commit.
このファイルに対するすべての変更を確認したい場合は、このファイルに対して行われたすべての変更を表示する新しいソース管理履歴インスペクタを開くことができ、すぐに任意のコミットにジャンプすることができます。

And because it's in the inspector, this now works for any file type in your project.
インスペクタ内にあるので、これはプロジェクト内のあらゆるファイルタイプに対して機能します。

To help you review local changes, we've also improved the change bar.
ローカルの変更を確認しやすくするために、変更バーも改善されました。

When I hover over the change bar, it shows me the local changes.
チェンジバーの上にカーソルを置くと、ローカルの変更が表示されます。

But I can now have it show me the code before the change that I made to get a quick snippet.
しかし、スニペットを手に入れるために行った変更の前に、コードを表示させることができます。

[ Applause ]
 【拍手】

And of course it's live, so as I start typing, it will update to keep me up-to-date.
そしてもちろん、それはライブです、私がタイプし始めるとき、それは私を最新にしておくために更新するでしょう。

So those are just some of the many source editing features you'll find in Xcode 11.
つまり、これらはXcode 11にある数多くのソース編集機能のほんの一部です。

[ Applause ]
 【拍手】

Okay, so testing is another key development workflow.
さて、それでテストはもう一つの重要な開発ワークフローです。

And Xcode already has great support for writing tests, which of course you all already know because you're writing lots of them, right?
そしてXcodeはすでにテストを書くことを大いにサポートしています。もちろん、たくさん書いているので、皆さんはすでに知っているでしょう。

>> Yep.
 >>うん。

>> Yeah.
 >>うん。

>> Excellent.
 >>優秀です。

That's what we like to hear.
それが私たちが聞きたいことです。

Now what you may not know is that Xcode can do even more with your tests by using fantastic tools like runtime issues, sanitizers, localization simulation.
今、あなたが知らないかもしれないことは、Xcodeがランタイム問題、消毒剤、ローカライゼーションシミュレーションのような素晴らしいツールを使うことによってあなたのテストでさらに多くをすることができるということです。

And we add more of these every year.
そして、私たちは毎年これらをもっと追加します。

With so many options, what's been missing is a way to combine them all in one place to be used in parallel.
非常に多くのオプションを使用した場合、欠けているのは、それらをすべて1か所にまとめて並列に使用する方法です。

And for that we are adding test plans.
そのために、テスト計画を追加しています。

Now the power of test plans comes from running your tests in many configurations.
テスト計画の威力は、さまざまな構成でテストを実行することによってもたらされます。

With a few simple selections, you can instantly test for your global audience.
いくつかの簡単な選択で、あなたは即座にあなたのグローバルオーディエンスをテストすることができます。

And this configuration is also perfect for capturing screenshots for the App Store or collecting details for your localizers.
また、この設定は、App Storeのスクリーンショットをキャプチャしたり、ローカライズ担当者のために詳細を収集したりするのにも最適です。

Yeah, it's okay to applaud for that.
ええ、それを称賛しても大丈夫です。

This is a big deal.
これは大したことです。

[ Applause ]
 【拍手】

You can then see your app from every angle by adding in other diagnostics, tools and parameters.
他の診断、ツール、パラメータを追加することで、あらゆる角度からアプリを見ることができます。

And your coverage increases even further when you run your test plans against many devices and OS combinations to get a fully comprehensive view of how your app is doing.
また、多くのデバイスとOSの組み合わせに対してテストプランを実行して、アプリケーションがどのように機能しているかを包括的に把握すると、カバレッジがさらに向上します。

Now for testing at this scale, test plans work perfectly with Xcode Server which can take full advantage of the new Mac Pro and with Xcode's new parallel testing on simulators and devices.
この規模でのテストでは、テスト計画は新しいMac Proを最大限に活用できるXcode Serverと、シミュレータとデバイスでのXcodeの新しい並行テストで完璧に機能します。

The result with test plans is you now have one command that does all of the testing for your apps.
テスト計画の結果は、アプリのすべてのテストを実行するコマンドが1つになりました。

So this is a major advancement.
だからこれは大きな進歩です。

[ Applause ]
 【拍手】

Now often when testing and debugging, it's necessary to replicate user scenarios.
テストやデバッグを行うときには、ユーザーシナリオを再現する必要があります。

And our new Device Conditions answers the call.
そして、私たちの新しいDevice Conditionsが電話に出ます。

You can now set varied conditions for network throughput and thermal states on your devices and see how your apps respond.
これで、デバイスのネットワークスループットと温度状態にさまざまな条件を設定し、アプリの反応を確認できます。

Now rest assured these are actually just simulations.
これらは実際には単なるシミュレーションです。

We're not actually going to make your devices get super-hot here.
私たちは実際にあなたのデバイスをここで過熱させるつもりはありません。

You can enable the conditions in Xcode's Devices window.
 Xcodeの「デバイス」ウインドウで条件を有効にできます。

And the devices will display banners when the conditions are active.
そして条件が活発なとき装置は旗を表示する。

You can tap the banner to disable the conditions and Xcode will automatically terminate the conditions when you disconnect the devices.
バナーをタップして条件を無効にすると、デバイスを取り外すとXcodeが自動的に条件を終了します。

Now for all the testing you're going to be doing, we've also improved our result bundles which are now standalone.
これで、これから実行しようとしているすべてのテストについて、結果バンドルが改善され、スタンドアロンになりました。

Whether you create them in Xcode or from the command line, you can share them via email, attach them to bugs and then just double-click on them to open them back in Xcode to review all of the details.
 Xcodeで作成しても、コマンドラインから作成しても、それらを電子メールで共有し、バグに添付してからダブルクリックするだけで詳細を確認できます。

[ Applause ]
 【拍手】

Now to help you improve your apps even further, we are introducing two new feedback tools.
アプリをさらに改良するために、2つの新しいフィードバックツールを紹介します。

First, app performance metrics for iOS and iPadOS App Store apps.
まず、iOSおよびiPadOS App Storeアプリのアプリパフォーマンス指標です。

When users opt into sharing analytics, you'll received anonymized metrics for battery life, launch time, memory use and more.
ユーザーが分析の共有を選択すると、バッテリ寿命、起動時間、メモリ使用量などについて匿名化されたメトリクスを受け取ることになります。

These metrics are aggregated and displayed in the organizer alongside the crash and energy logs, and are a great way to monitor and improve the performance of your app with each build.
これらのメトリクスは、クラッシュログとエネルギーログと一緒にまとめられてオーガナイザーに表示されます。これは、ビルドごとにアプリのパフォーマンスを監視および改善するための優れた方法です。

These aggregated metrics, we started collecting them in the spring with iOS 12.2.
これらの集約された測定基準は、私たちはiOS 12.2で春にそれらを集め始めました。

So many of your apps will already have data to review.
だからあなたのアプリの多くはすでにレビューするデータを持っているでしょう。

Now another great source of feedback is directly from your users, and Test Flight will now let users share what they think.
フィードバックのもう1つの優れた情報源は、ユーザーからの直接のものです。TestFlightでは、ユーザーが自分の考えを共有できるようになります。

Test Flight apps automatically enable user feedback.
 Test Flightアプリは自動的にユーザーフィードバックを有効にします。

When a user takes a screenshot in your app, they will have a new option to share it as beta feedback, optionally adding in their comments.
ユーザーがあなたのアプリでスクリーンショットを撮るとき、彼らはベータフィードバックとしてそれを共有するための新しいオプションを持つでしょう。

[ Applause ]
 【拍手】

You can review all the feedback on App Store Connect and download all the details for your bug tracking systems.
 App Store Connectに関するすべてのフィードバックを確認して、バグ追跡システムに関する詳細をすべてダウンロードできます。

So all these features today are just a small taste of our Xcode release, which brings together innovations in Swift, the SDK and across all of our tools.
したがって、今日のこれらすべての機能は、Swift、SDK、およびすべてのツールのイノベーションをまとめたXcodeリリースのほんの一部に過ぎません。

All this to help you do your best work faster than ever.
あなたがこれまで以上に速くあなたの最善の仕事をするのを助けるためのこれらすべて。

And that is Xcode 11.
それがXcode 11です。

[ Applause ]
 【拍手】

>> And now I'd like to invite Sebastien back to tell us more about Apple's platforms.
 >>そして今、私はSebastienを招待してAppleのプラットフォームについてもっと教えて欲しい。

Sebastien?
セバスチャン？

[ Applause ]
 【拍手】

>> Thank you, Matthew.
 >>ありがとう、マシュー。

Wasn't that amazing?
それほど素晴らしかったですか？

Really, really great features to help all of you build better apps.
本当に、あなた全員がより良いアプリケーションを構築するのを助けるための本当に素晴らしい機能。

So now let's switch to our platforms.
それでは、プラットフォームに切り替えましょう。

And of course our platforms themselves are tailored to provide great experiences and they really reflect the unique way in which each of them is used.
そしてもちろん、私たちのプラットフォーム自体は素晴らしい経験を提供するように調整されており、それらはそれぞれが使われるユニークな方法を本当に反映しています。

So some of what we're doing this year is unique to each of them, and what we're going to do now is dive right in to macOS and tell you what we're doing there.
ですから、今年行っていることのいくつかはそれぞれの人にとってユニークなものです。そしてこれからやろうとしていることは、macOSに飛び込んで、そこで行っていることをあなたに伝えることです。

macOS Catalina is a great release with a rich set of compelling new features such as screen time and the new Music app.
 macOS Catalinaは、スクリーンタイムや新しいMusicアプリなど、魅力的な新機能が豊富に揃った素晴らしいリリースです。

And the Mac takes another great step forward with amazing productivity features such as Sidecar.
そして、MacはSidecarのような驚くべき生産性機能でもう一つの大きな前進をする。

We're going to love Sidecar, right?
私たちはサイドカーを好きになるでしょうね。

[ Applause ]
 【拍手】

All right.
大丈夫。

Well, with an active installed base of over 100 million users, the Mac is a vibrant platform with a rich app ecosystem.
 1億人を超えるユーザーが活発にインストールされているMacは、豊富なアプリエコシステムを備えた活気のあるプラットフォームです。

And the Mac ecosystem is full of powerful native apps that you have created using our AppKit framework.
そして、Macエコシステムは、あなたが私たちのAppKitフレームワークを使って作成した強力なネイティブアプリケーションでいっぱいです。

And a great example of this is Pixelmator Pro.
そしてその好例がPixelmator Proです。

Now AppKit is the powerful framework that enables the full capabilities of the Mac.
今AppKitはMacの全機能を可能にする強力なフレームワークです。

But we also recognize that there are a number of apps available for iPad that would be great to run on the Mac, but you have not always had time to use AppKit to bring that to the Mac.
しかし、私たちはまた、iPad上でMac上で実行するのに最適なアプリケーションがいくつかあることを認識していますが、それをMacにもたらすためにAppKitを使用する時間が常にあるとは限りません。

And so this year we're adding an additional way to create native Mac apps with the technology that allows you to take an iPadOS app and bring it to the Mac with minimal effort.
そこで今年は、iPadOSアプリを使って最小限の労力でそれをMacに持ち込むことができるテクノロジを使って、ネイティブのMacアプリを作成する方法を追加します。

We -- Can you go back two slides?
私たち - あなたは2枚のスライドに戻ることができますか？

Sorry.
ごめんなさい。

One more.
もう一つ。

All right.
大丈夫。

This is a huge opportunity for the Mac to tap into the world's largest app ecosystem.
これは、Macが世界最大のアプリエコシステムを活用する大きなチャンスです。

There are over a million iPad apps out there and we think many of them would be really great on the Mac as well.
そこには何百万ものiPadアプリが出回っています、そしてそれらの多くはMac上でも本当に素晴らしいものになると思います。

Now to achieve this, we've ported more than 40 frameworks and libraries from iOS to the Mac.
これを達成するために、40以上のフレームワークとライブラリをiOSからMacに移植しました。

And if you're an existing iOS developer that doesn't have a Mac app yet, you're going to love having the same APIs available on both platforms.
まだMacアプリを持っていない既存のiOS開発者であれば、両方のプラットフォームで同じAPIを利用できるようにするのが好きになるでしょう。

In fact, we've made available almost the entire iOS API set with only a small number of exceptions for unique mobile features.
実際、私たちはほとんどすべてのiOS APIセットを利用可能にしましたが、ユニークなモバイル機能についてはごく少数の例外があります。

Now we achieved this by adapting UI Kit as a native framework.
現在は、UI Kitをネイティブフレームワークとして採用することでこれを達成しました。

That enables iPad apps to run on the Mac and feel just as fast and fluid as other apps on the platform.
これにより、iPadアプリをMac上で実行し、プラットフォーム上の他のアプリと同じくらい速くて流動的に感じることができます。

And by integrating UI Kit directly into macOS, many of the fundamentals are automatic.
そして、UI Kitを直接macOSに統合することによって、基本の多くは自動的に行われます。

So many Mac desktop and windowing features are added without any work on your part, and we adapt platform-unique elements like touch controls to keyboard and mouse input, saving you a ton of work and giving you a huge head start in your development.
 Macのデスクトップ機能やウィンドウ機能の多くは何もせずに追加されています。また、タッチコントロールのようなプラットフォーム固有の要素をキーボードやマウスの入力に適応させるので、作業量が大幅に削減されます。

Now we've been working on this technology for a number of years and we're using it for our own apps, which has allowed us to prove out and refine the technology before we make it available to you in macOS Catalina this year.
今、私たちは何年も前からこの技術に取り組んできました、そして私たちはそれを我々自身のアプリのために使っています。

If you have an iPadOS app, targeting the Mac is super easy.
あなたがiPadOSアプリを持っているなら、Macをターゲットにすることはとても簡単です。

There are basically three steps.
基本的に3つのステップがあります。

First, click the checkbox in Xcode -- here we go.
まず、Xcodeのチェックボックスをクリックしてください - ここに行きます。

[ Laughter ]
[ 笑い ]

That easy.
それは簡単です。

In Xcode's Project Editor, and turn on Mac support for your project.
Xcodeのプロジェクトエディタで、プロジェクトのMacサポートをオンにします。

There you go.
そこに行きます。

As easy as that.
それと同じくらい簡単です。

And here's the magic.
そしてこれが魔法です。

That single project and target builds apps for all three platforms.
その単一のプロジェクトとターゲットは、3つすべてのプラットフォーム用のアプリケーションを構築します。

And when you make a change to your source, all three apps update automatically.
そしてあなたがあなたのソースに変更を加えると、3つのアプリケーションすべてが自動的に更新されます。

The second step is to ensure that your app is great on the iPad.
2番目のステップはあなたのアプリがiPad上で素晴らしいことを確認することです。

Better iPad apps make better Mac apps as well.
より良いiPadアプリは、より良いMacアプリにもなります。

So the work that you put in to adopting the newest technologies and optimizing for larger iPad screens translates wonderfully to the Mac.
そのため、最新のテクノロジを採用し、より大きなiPadスクリーン用に最適化するためにあなたが投入した作業は、驚くほどMacに変換されます。

Just following best practices such as supporting external keyboards will also result in richer Mac experiences.
外付けキーボードのサポートなど、ベストプラクティスに従うだけでも、Macの経験が豊かになります。

The third step is to take advantage of specific Mac capabilities.
3番目のステップは、特定のMacの機能を利用することです。

And this is where you make customizations that take full advantage of typical Mac-specific user interface elements like full menus and toolbars.
これが、フルメニューやツールバーのような典型的なMac特有のユーザーインターフェース要素を最大限に活用するカスタマイズをするところです。

And if applicable, sidebars and their special materials.
また、該当する場合はサイドバーとその特別な素材も使用します。

Now to show you how easy this is, I'd like to invite Matthew back onstage for a demo.
これがいかに簡単であるかを示すために、デモのためにステージ上でMatthewを招待したいと思います。

Matthew?
マシュー？

[ Applause ]
【拍手】

>> Thank you, Sebastien.
>>ありがとう、Sebastien。

Here we have our travel application running in the iPad Simulator.
ここでは、iPad Simulatorで旅行アプリケーションを実行しています。

It's a list view of locations.
場所のリストビューです。

When I select a location, the globe will rotate.
場所を選択すると、地球が回転します。

And we have a logging area where I can start keeping track of my trips in a journal.
そして、私たちは日記の中で私の旅行を追跡し始めることができる伐採場所を持っています。

Let's follow Sebastien's three steps and bring this app to the Mac.
Sebastienの3つのステップに従って、このアプリをMacに持ってきましょう。

Step one, check the box.
ステップ1、ボックスをチェックしてください。

I'll quit the simulator and here in the target editor I'll check the box for Mac support to enable it.
私はシミュレータを終了し、ここでターゲットエディタでそれを有効にするためにMacサポートのためのボックスをチェックします。

That's it.
それでおしまい。

I can now build and run my application for the Mac.
これで、Mac用に自分のアプリケーションをビルドして実行することができます。

By checking the box, we added the Mac as a destination.
チェックボックスをオンにして、送信先としてMacを追加しました。

So just like I can pick between devices and simulators for my app, I can now choose the Mac.
だから私は私のアプリのためのデバイスとシミュレータの間で選ぶことができるのと同じように、私は今Macを選ぶことができます。

And here's the Mac app.
そして、これがMacアプリです。

List View on the left, select the location and log in.
左側のリストビューで、場所を選択してログインします。

[ Applause ]
【拍手】

I know, pretty powerful checkbox.
とても強力なチェックボックスです。

All right, let's move on to step two, make a great iPad app.
それでは、ステップ2に進みましょう。素晴らしいiPadアプリを作成しましょう。

I've not implemented any actions from my List View, things like Adding to Favorites or to Share.
私は自分のリストビューからアクションを実装していません。お気に入りへの追加や共有への追加などです。

When I implement those for the iPad, they'll show up as a context menu on the Mac.
iPad用にそれらを実装すると、それらはMac上でコンテキストメニューとして表示されます。

It's a double win.
それは二重の勝利です。

So I'll quit the Mac app and change to my sidebar controller here, and I'll just add a table view delegate method that sets up those menus for each item.
それで、私はここでMacアプリを終了し、私のサイドバーコントローラに変更し、そして各項目のためにそれらのメニューを設定するテーブルビューデリゲートメソッドを追加するだけです。

Okay.
はい。

Let's move on to step three.
ステップ3に進みましょう。

I'd like the sidebar on my Mac app to be vibrant.
私のMacアプリのサイドバーを元気にしてもらいたい。

Now this change doesn't happen automatically because it's something you should review to make sure it's appropriate.
現在、この変更は自動的には発生しません。適切であることを確認するために確認する必要があるためです。

When you do find it's what you'd like, it's a simple one-line change to set the background style to sidebar.
あなたがそれがあなたが望むものであることを見つけたとき、それは背景スタイルをサイドバーに設定するための簡単な一行の変更です。

Okay, for our final change, I'd like to add a menu bar to our application.
それでは、最後の変更として、アプリケーションにメニューバーを追加したいと思います。

So here in the storyboard I'll bring up the library and I'll search for a menu.
そこでここではストーリーボードでライブラリを立ち上げてメニューを検索します。

I'll grab a main menu and I'll drag it out into my storyboard and we'll open up the file menu.
メインメニューをつかみ、ストーリーボードにドラッグして、ファイルメニューを開きます。

I'd like to add a menu command in here for the login action.
ログインアクションのためのメニューコマンドをここに追加したいのですが。

So we'll call this Login.
だから我々はこれをLoginと呼びます。

We'll give it a key equivalent of Command-L.
Command-Lと同等のものにします。

And I just now need to connect the menu item up to the action that I'm already using for Login.
そして今、私はメニュー項目を私がすでにログインに使っているアクションに接続する必要があります。

Okay?
はい？

That's it.
それでおしまい。

Let's build and run our changes.
変更をビルドして実行しましょう。

I'm going to go up and hide Xcode for the moment so we can see our application.
私たちはアプリケーションを見ることができるように、しばらくの間Xcodeを上に隠して隠そうとしています。

Okay, so now we have the vibrant sidebar.
さて、今、私たちは活気に満ちたサイドバーを持っています。

When I select an item, I can bring up a context menu and up here in the File menu I now have the Login action.
項目を選択すると、コンテキストメニューが表示され、[ファイル]メニューの[ログイン]アクションが表示されます。

So just like that, three easy steps.
それで、ちょうどそのように、3つの簡単なステップ。

[ Applause ]
【拍手】

Three easy steps to bring our app to the Mac and make a great user experience for all our users.
アプリをMacに移行し、すべてのユーザーに優れたユーザーエクスペリエンスを提供するための3つの簡単な手順。

Back to you, Sebastien.
あなたに戻って、Sebastien。

[ Applause ]
【拍手】

>> Thank you, Matthew.
>>ありがとう、マシュー。

That was really amazing.
本当にすごかったです。

Doesn't this make you want to go and try it out?
これはあなたが行って試してみたくないのですか？

Yes.
はい。

All right, in fact, over the last few weeks we invited a number of developers to take this for a spin.
実際のところ、ここ数週間で私たちはこれを試しに回すように多くの開発者を招待しました。

And the progress that they have made in a few short weeks is truly impressive.
そして、彼らが数週間で成し遂げた進歩は、本当に印象的です。

Here's a sample of the iPad apps that they already have running on the Mac.
これは、すでにMac上で実行されているiPadアプリのサンプルです。

Now once you've built a Mac app, the best way to distribute it to your users is through the Mac App Store.
Macアプリを作成したら、それをユーザーに配布する最善の方法はMac App Storeを使用することです。

It features the biggest catalog of Mac Apps.
それはMacアプリの最大のカタログを特徴とします。

It's available in 155 countries throughout the world and the Mac App Store allows you to reach every single Mac user.
それは世界中の155カ国で利用可能であり、そしてMac App Storeはあなたがあらゆる一人のMacユーザと連絡をとることを可能にする。

Now we also built Gatekeeper to give users flexibility and choice on how they get their apps while helping protect them from malicious software.
また、ゲートキーパーを構築して、悪意のあるソフトウェアからユーザーを保護しながら、ユーザーが柔軟にアプリケーションを入手する方法を選択できるようにしました。

And in macOS Catalina, Gatekeeper will validate the apps that you run from the internet both at first launch and periodically thereafter to confirm that they're free of known malware.
そしてmacOS Catalinaでは、Gatekeeperは最初の起動時とその後定期的にインターネットから実行するアプリを検証して、既知のマルウェアがないことを確認します。

This is accomplished by requiring developers to use the notarization service that we announced last year for both new and updated apps.
これは、開発者に、昨年発表した公証サービスを新しいアプリと更新したアプリの両方に使用するように要求することで達成されます。

So now you and your users can safely get apps from both the Mac App Store and the internet.
だから今、あなたとあなたのユーザは安全にMac App Storeとインターネットの両方からアプリを手に入れることができます。

Notarization has already seen broad adoption.
公証はすでに広く採用されています。

It's simple and fast with over 98% of submissions completing within 15 minutes.
それは15分以内に完成した提出物の98％以上で簡単で速いです。

Now speaking of security, we're continuing to invest in the foundations of macOS and I'd like to focus on three areas.
今セキュリティについて言えば、私たちはmacOSの基礎に投資し続けています、そして私は3つの領域に焦点を合わせたいと思います。

First, a new technology called Driver Kit which allows you to move your kernel extensions out of the kernel and into user space.
まず、Driver Kitと呼ばれる新しいテクノロジで、カーネルの拡張機能をカーネルからユーザー空間に移動できます。

And by running these drivers and extensions as user processes, we improve the stability of macOS for all of our users.
そして、これらのドライバや拡張機能をユーザープロセスとして実行することで、私たちはすべてのユーザーにとってmacOSの安定性を向上させます。

We identified the most common use cases that have required kernel extensions in the past, and now we have a user space alternative for over 75% of them in macOS Catalina.
過去にカーネルエクステンションを必要とした最も一般的なユースケースを特定しました。そして今では、それらの75％以上をmacOS Catalinaで代替するユーザースペースがあります。

We encourage you to adopt Driver Kit as future versions of macOS will no longer run these types of kernel extensions.
今後のバージョンのmacOSでは、これらの種類のカーネル拡張機能が実行されなくなるため、Driver Kitを採用することをお勧めします。

Next, we're improving the stability of macOS by making the system volume read-only.
次に、システムボリュームを読み取り専用にすることで、macOSの安定性を向上させています。

Here's how it works.
これがどのように機能するかです。

Today there's a single volume that includes user data, apps and the operating system.
今日は、ユーザーデータ、アプリ、オペレーティングシステムを含む単一のボリュームがあります。

And to further isolate macOS from changes, the Mac will now be divided into two logical volumes.
そしてさらにmacOSを変更から隔離するために、Macは2つの論理ボリュームに分割されます。

One for the operating system files which will be read-only, and the other for user data and apps.
一方は読み取り専用になるオペレーティングシステムファイル用、もう一方はユーザーデータとアプリケーション用です。

[ Applause ]
【拍手】

There you go.
そこに行きます。

[ Applause ]
【拍手】

This will further protect the operating system from changes, increase stability and set us up to deliver future security benefits.
これにより、オペレーティングシステムを変更からさらに保護し、安定性を高め、将来のセキュリティ上の利点を提供できるようにします。

Now some of you may have made assumptions in your app or your installer, and you'll want to check that it works seamlessly on macOS Catalina.
今あなたの何人かはあなたのアプリやあなたのインストーラで仮定をしたかもしれません、そしてあなたはそれがmacOS Catalinaでシームレスに動作することをチェックしたいでしょう。

Finally, enhancements to app and data protection.
最後に、アプリとデータ保護の強化。

We have spent the last few years adding additional data protection categories so that users are in control of which apps can access important files like your photos or sensitive sensors like your camera and microphone on your Mac.
ここ数年は、ユーザーが写真などの重要なファイルや、Macのカメラやマイクなどの機密センサーにアクセスできるかどうかをユーザーが制御できるように、データ保護のカテゴリを追加してきました。

In macOS Catalina, we're continuing this work by ensuring that apps seek permission before capturing input events, so things like key presses or screen recordings.
macOS Catalinaでは、入力イベントをキャプチャする前にアプリが許可を求めていることを確認することで、この作業を続けています。これにより、キープレスや画面録画などが可能になります。

And we're also going to protect user data on your Mac, so apps will now have to seek permission before accessing the files that users keep on their desktop, downloads, documents, iCloud drive and external drives.
また、Mac上のユーザーデータを保護するため、ユーザーがデスクトップに保存しているファイル、ダウンロード、ドキュメント、iCloudドライブ、外付けドライブにアクセスする前に、アプリが許可を取得する必要があります。

Yeah.
ええ

[ Applause ]
【拍手】

We are really excited about all the enhancements that we're bringing in macOS Catalina.
私たちはmacOS Catalinaでもたらしているすべての機能強化に本当に興奮しています。

Now another platform that's got some really big changes this year is watchOS.
今年、本当に大きな変化をもたらしたもう1つのプラットフォームは、watchOSです。

And to tell you more, I'd like to invite Lori up on stage.
そして、もっと詳しく言うと、私はLoriをステージに招待したいのですが。

Lori?
ロリ？

[ Applause ]
【拍手】

>> Thanks, Sebastien.
>>ありがとう、Sebastien。

[ Applause ]
【拍手】

This morning we introduced a bunch of cool new features in watchOS 6, including new health apps like noise and cycle tracking, activity trends, audiobooks and more.
今朝、watchOS 6のクールで新しい機能の多くを紹介しました。それには、ノイズやサイクルの追跡、活動の傾向、オーディオブックなどの新しい健康アプリが含まれます。

But the real story for watchOS 6 is that it's now possible to declare independence from the phone and build fully watch-focused experiences.
しかし、watchOS 6の本当の話は、電話からの独立を宣言し、完全に監視に焦点を絞ったエクスペリエンスを構築することが可能になったということです。

[ Applause ]
【拍手】

Thanks to cellular connectivity, customers are increasingly leaving their phones behind and enjoying the freedom using just their Apple Watch to stay connected.
携帯電話の接続性のおかげで、顧客はますます電話を置き去りにし、接続を維持するためにApple Watchだけを使って自由を楽しんでいます。

From running errands to running workouts, from listening to music to chatting with friends, we want all users to enjoy great Apple Watch experiences without limitations.
音楽を聴くことから友人とチャットすることまで、用事を実行することからトレーニングを実行することまで、すべてのユーザーが素晴らしいApple Watch体験を制限なく楽しむことを望みます。

And independent watch apps make that possible.
独立した監視アプリがそれを可能にします。

We've taken a good look at the challenges of developing for Apple Watch and worked hard not only to bring you new APIs that make it possible to support independent experiences, but also to completely revamp the experience of being an Apple Watch developer.
私たちはApple Watchのために開発することの課題をよく見て、独立した経験をサポートすることを可能にする新しいAPIをあなたにもたらすだけでなく、Apple Watch開発者である経験を完全に刷新するために一生懸命働きました。

What if I told you it was possible to create a watch app that's only a watch app?
私はあなたが時計アプリだけである時計アプリを作成することが可能であるとあなたに言ったならばどうでしょうか？

If you've got an idea for a great watch-only experience, Xcode now makes it simple to create a watch app that's just a watch app.
優れた監視専用のエクスペリエンスのアイデアがある場合は、Xcodeを使用することで、単なる監視アプリケーションである監視アプリケーションを簡単に作成できます。

So you can pursue your idea without also having to build an iOS app.
そのため、iOSアプリを作成しなくても、アイデアを追求できます。

And if you already have an iOS app, you can still build your app to be completely independent of its companion thanks to a couple key changes we made in watchOS 6 to support watch-only apps, including making Apple Watch a standalone push target.
また、iOSアプリをすでにお持ちの場合でも、Apple Watchをスタンドアロンプ​​ッシュターゲットにするなど、watchOS 6でいくつかの重要な変更を加えたことで、そのアプリから完全に独立したアプリを作成できます。

You now have the option of sending notifications directly to the watch so you can update both your users and your apps data without relying on the phone to mediate.
あなたは仲介するために電話に頼ることなくあなたのユーザーとあなたのアプリデータの両方を更新することができるように今すぐあなたは腕時計に直接通知を送るオプションを持っています。

[ Applause ]
【拍手】

We're also supporting Cloud Kit subscriptions and complication pushes to help you keep your app up-to-date.
また、Cloud Kitのサブスクリプションや複雑なプッシュをサポートしているため、アプリを最新の状態に保つことができます。

And since asking users to sign in on iPhone is not an option when you don't have an iPhone app, in watchOS 6 we're giving you text fields so you can offer account creation and sign-in options directly on Apple Watch.
また、iPhoneアプリケーションをお持ちでない場合は、iPhoneへのサインインをユーザーに依頼することはできませんので、watchOS 6ではテキストフィールドを用意しているので、Apple Watchでアカウントの作成とサインインのオプションを直接提供できます。

If you want to make account creation really easy, you can even add an Assign with Apple button to your app to let your users set up an account and sign in with the Apple ID they already have.
アカウントの作成を非常に簡単にしたい場合は、Appleに割り当てボタンをアプリに追加して、ユーザーがアカウントを設定し、すでに持っているApple IDでサインインできるようにすることもできます。

No new passwords or text entry required.
新しいパスワードやテキスト入力は不要です。

With watchOS 6 we're also addressing a common watch-only use case by bringing streaming audio to watchOS.
watchOS 6では、ストリーミングオーディオをwatchOSに持ち込むことで、一般的な監視専用のユースケースにも対処しています。

We introduced background audio playback in watchOS 5 for local files.
ローカルファイル用にwatchOS 5でバックグラウンドオーディオ再生を導入しました。

And now in watchOS 6, we've brought three ways to stream audio directly to Apple Watch by making Network,framework, NSURLsessionStreamTask and even more of AVFoundation available to you.
そして今やwatchOS 6では、ネットワーク、フレームワーク、NSURLsessionStreamTaskそしてさらに多くのAVFoundationを利用可能にすることによってオーディオをApple Watchに直接ストリーミングするための3つの方法をもたらしました。

We also recognize that there are use cases beyond audio playback, workouts and navigation where you need to keep your app running order to complete a task.
また、オーディオ再生、トレーニング、ナビゲーション以外にも、タスクを完了するためにアプリの実行順序を維持する必要があるユースケースがあることも認識しています。

For example, a meditation session.
たとえば、瞑想セッションです。

In watchOS 6, we're introducing a new extended runtime API that gives more apps a way to stay running even after the user lowers their wrist.
watchOS 6では、ユーザーが手首を下げた後でも、より多くのアプリを実行し続ける方法を提供する新しい拡張ランタイムAPIを導入しています。

This enables new app experiences in self-care, mindfulness, physical therapy, smart alarms and health monitoring.
これにより、セルフケア、マインドフルネス、理学療法、スマートアラーム、ヘルスモニタリングにおける新しいアプリ体験が可能になります。

That's a lot of new APIs and capabilities.
それはたくさんの新しいAPIと機能です。

If only you had more options for creating a compelling user interface, right?
魅力的なユーザーインターフェースを作成するための選択肢が他にもあるのであれば、そうでしょうか。

We know you've been asking for a more advanced UI framework on the watch for years.
私たちはあなたが何年もの間、より高度なUIフレームワークを求めてきたことを知っています。

And in watchOS 6 we finally have one with SwiftUI.
そしてwatchOS 6では、ついにSwiftUIのものができました。

[ Applause ]
【拍手】

You've already seen SwiftUI on iOS.
あなたはすでにiOSでSwiftUIを見ました。

That same declarative language for defining beautiful user interfaces is available for watchOS as well, expanding what's possible on the platform.
美しいユーザーインターフェースを定義するための同じ宣言型言語は、watchOSでも利用可能で、プラットフォーム上で可能なことを拡張します。

From lists with swipe to delete, reordering and carousel filing, to direct access, the digital crown, it's easier than ever to create a compelling watch experience.
スワイプ付きのリストから削除、並べ替え、カルーセルファイリング、直接アクセス、デジタルクラウンまで、魅力的な時計体験を作成するのはこれまでになく簡単です。

Let me show you how to start making use of some of the new independent app features with SwiftUI.
SwiftUIを使って新しい独立型アプリの機能を利用する方法を説明しましょう。

Okay, so I've got my travel app running here in the Simulator and I've already started updating it using SwiftUI, so it's starting to look great.
さて、私はここでシミュレータで私の旅行アプリを走らせています、そして私はSwiftUIを使ってそれを更新し始めたので、それは素晴らしく見え始めています。

But I still have some work to do beyond layout because my Sign In button currently just asks users to sign in on iPhone.
しかし、私の「サインイン」ボタンは現在iPhoneにサインインするようにユーザーに要求しているだけなので、レイアウト以外にもやるべきことがいくつかあります。

And my users have told me that is not what they want.
そして私のユーザーは私に彼らが望むものではないと言った。

They want to be able to do everything right on their wrist.
彼らは自分の手首ですべてを正しくできるようにしたいのです。

So I'm going to quit the simulator and go over to my project file.
だから私はシミュレータを終了し、私のプロジェクトファイルに行くつもりです。

And I'll move to my travel watch extension target and declare independence from phone by checking the Supports Running Without iOS App Installation box.
そして、私は自分のTravel Watch拡張機能ターゲットに移動し、iOSアプリをインストールせずにサポートを実行するボックスをチェックして、電話からの独立を宣言します。

Next I'm going to go to the Sign In view that I've already started.
次に、すでに開始した[サインイン]ビューに移動します。

I'll resume my previews.
プレビューを再開します。

Great.
すばらしいです。

And you can see I have a Sign In button here and two previews.
そして、ここにサインインボタンと2つのプレビューがあります。

The top one is for English which is the language that I speak and the bottom one I'm starting to experiment with localizing my app into Arabic which is a right-to-left language.
一番上のものは私が話す言語である英語のためのものであり、一番下のものは私のアプリを右から左への言語であるアラビア語にローカライズすることで実験し始めています。

So the first thing I'm going to do is add a field for my Username button.
だから私がやろうとしている最初のことは私のユーザー名ボタンのフィールドを追加することです。

And I'm going to bind this to my -- oops.
そしてこれを私のおっとに結び付けるつもりです。

To my username state so that the field updates as the value changes.
値が変わるとフィールドが更新されるように、私のユーザー名の状態にします。

Notice I've set the placeholder text to username so I give the user a chance to figure out what to do with this field.
プレースホルダのテキストをusernameに設定したので、このフィールドで何をするべきかをユーザーに理解させる機会を与えます。

And I've also set the content type to username so that password and username autofill works when using continuity keyboard.
また、継続キーボードを使用するときにパスワードとユーザー名の自動入力が機能するように、コンテンツタイプをusernameに設定しました。

Next I'm going to add a password field, and for this I want to use a secure field so that people can't spy on me when I'm typing my password.
次にパスワードフィールドを追加します。このために、パスワードを入力しているときに他のユーザーが私を覗き見しないように、安全なフィールドを使用します。

And again, I'm going to bind this to my password state.
繰り返しますが、これを自分のパスワード状態にバインドします。

I've got a password placeholder text and again I'm using the content type of Password for autofill purposes.
パスワードのプレースホルダテキストを持っていますが、ここでも自動入力の目的でコンテンツタイプのPasswordを使用しています。

So that looks great in both English and Arabic.
だからそれは英語とアラビア語の両方で素晴らしく見えます。

And for Arabic it's pulling the strings right out of my localizable strings file.
アラビア語の場合は、ローカライズ可能なstringsファイルから文字列を取り出します。

This is not placeholder content.
これはプレースホルダーのコンテンツではありません。

Okay.
はい。

Above this, what I want to do is add a Sign In With Apple button because I think that's how users are really going to want to sign in.
この上に、私がやりたいのはAppleボタンでサインインすることです。ユーザーが本当にサインインしようとしているのだと思うからです。

So now I put that right at the top and then add a separator so it's clear that users have an option of signing in with their Apple ID or creating a customer username and password for my app.
それで、今私はそれを一番上に置いて、それからセパレーターを加えます、それでユーザーが彼らのApple IDでサインインするか、または私のアプリのために顧客ユーザー名とパスワードを作成するオプションがあるのは明らかです。

That looks great.
それは素晴らしいですね。

So the last step is to go over to my hosting controller and change my destination for my presentation button to the Sign In view that I just created instead of the Sign In on iPhone view.
最後のステップは、ホスティングコントローラに移動して、プレゼンテーションボタンの表示先を、[iPhoneでサインイン]ビューではなく、作成したばかりの[サインイン]ビューに変更することです。

So I got that going and now I want to turn on Live Preview, so all my buttons become interactive.
それで、私はそのようになりました、そして今私はライブプレビューをオンにしたいです、それで私のすべてのボタンはインタラクティブになります。

And then when I click on my Sign In button, I get my form.
サインインボタンをクリックすると、フォームが表示されます。

Sign In With Apple, or sign in with a username and password.
Appleでサインインするか、ユーザー名とパスワードでサインインします。

That looks great.
それは素晴らしいですね。

And that is creating a sign-in form on the Apple Watch with SwiftUI.
そして、それがSwiftUIを使ったApple Watchでのサインインフォームの作成です。

[ Applause ]
【拍手】

Okay.
はい。

So you've got the tools to build a great independent Apple Watch experience.
それで、あなたは素晴らしい独立したApple Watch経験を築くためのツールを手に入れました。

How are you going to get your app in front of customers with the least friction possible?
摩擦を最小限に抑えて、アプリをどのようにして顧客の前に配置するのですか。

The App Store and Apple Watch will be highlighting great independent apps through curated collections and editorial selections at the top level of the App Store.
App StoreとApple Watchは、App Storeのトップレベルでのコレクションの収集と編集による選択を通じて、優れた独立系アプリケーションを紹介します。

We're emphasizing independent apps here so users can get the instant gratification of being able to download and start using your awesome apps right away, whether they have the phone with them or not.
ここでは、独立したアプリを強調しているので、ユーザーは自分の素晴らしいアプリをダウンロードしてすぐに使い始めることができるかどうかにかかわらず、携帯電話を持っているかどうかに関係なくすぐに利用できます。

And when you dive into individual product pages, you'll see that this isn't just a pared down experience.
そして、個々の製品ページに飛び込むと、これは単なる経験の縮小ではないことがわかります。

Users will see full featured app descriptions, screenshots, reviews and more.
ユーザーは、フル機能のアプリの説明、スクリーンショット、レビューなどを見ることができます。

They can search for apps with dictation or scribble.
彼らは口述や落書きでアプリを検索することができます。

And they'll be able to download your apps directly to their wrists, thanks to app and asset thinning which make it possible to deliver a small bundle with only the architecture and assets that makes sense for the current watch.
現在の監視にとって意味のあるアーキテクチャとアセットのみで小さなバンドルを提供することを可能にするアプリとアセットの間引きのおかげで、彼らはあなたのアプリを手首に直接ダウンロードすることができるでしょう。

If you have both an iOS and a watchOS app, this will make your iOS app smaller too, as we're no longer downloading the watch bundle to the phone and then shuttling it over.
あなたがiOSとwatchOSの両方のアプリを持っているならば、我々はもはや電話に監視バンドルをダウンロードしてそれからそれをやり直さないので、これはあなたのiOSアプリも小さくするでしょう。

This is truly a whole new era for Apple Watch apps to be more functional, more beautiful and more independent than ever.
これは、Apple Watchアプリがこれまで以上に機能的で、美しくそして独立したものになるための全く新しい時代です。

We think both you and your customers are going to love this.
私たちはあなたとあなたの顧客の両方がこれを気に入ると思います。

And now to talk about the platform that we just declared independence from, I'd like to welcome Cindy to the stage.
そして今、私たちが独立を宣言したばかりのプラットフォームについて話すために、私はCindyをステージに歓迎したいと思います。

[ Applause ]
【拍手】

>> Thank you, Lori.
>>ありがとう、ロリ。

iOS 13 is a big release.
iOS 13は大きなリリースです。

You saw this morning that we have a ton of new features and enhancements like a redesigned share sheet, a Quick Type keyboard and a brand-new CarPlay experience.
今朝、私たちは再設計されたシェアシート、Quick Typeキーボード、そしてまったく新しいCarPlay体験のようなたくさんの新機能と強化を持っていることを見ました。

In addition to all of that, we took a good long look at our UI and gave iOS 13 a brand new look.
そのすべてに加えて、私たちはUIをよく見直して、iOS 13にまったく新しい外観を与えました。

This new look includes Dark Mode, cards, contextual actions and symbols.
この新しい外観には、ダークモード、カード、状況に応じた動作、およびシンボルが含まれています。

Let's dive into the incredibly cool new Dark Mode.
信じられないほどクールな新しいダークモードに飛び込みましょう。

Dark mode keeps the brightness down and gets Chrome out of the way so you can focus on just content.
ダークモードは明るさを抑え、Chromeを邪魔にならないようにしてコンテンツだけに集中できるようにします。

The entire system has been really thoughtfully updated and refined to look amazing.
システム全体が本当に思慮深く更新され、素晴らしいように洗練されました。

Your users are definitely going to want this.
あなたのユーザーは間違いなくこれを望んでいるでしょう。

And to help you bring these same refinements to your apps, we've created some new APIs designed specifically with Dark Mode in mind.
そして、あなたがあなたのアプリにこれらの同じ洗練をもたらすのを助けるために、我々はDarkモードを念頭に置いて特別に設計されたいくつかの新しいAPIを作成しました。

But first it's semantic colors.
しかし、最初は意味色です。

There are new colors for backgrounds, fills and text.
背景、塗りつぶし、テキストに新しい色があります。

And in Dark Mode, they have multiple variants to give your app a visual hierarchy.
また、ダークモードでは、アプリに視覚的な階層を持たせるための複数のバリエーションがあります。

Now what does that mean?
今それはどういう意味ですか？

Well, when your app is full-screen, its background is pure black.
さて、あなたのアプリがフルスクリーンであるとき、その背景は真っ黒です。

To ensure sufficient contrast, UI presented above it takes on a brighter color palette.
十分なコントラストを確保するために、上記のUIはより明るいカラーパレットを使用しています。

When multitasking on iPad, the slide-over app and side-by-side apps also render in these lighter layer colors.
iPadでマルチタスクを実行すると、スライドオーバーアプリとサイドバイサイドアプリもこれらの明るいレイヤーの色でレンダリングされます。

There is a lot of nuance to this design, but you'll get it automatically with semantic colors.
このデザインには多くのニュアンスがありますが、セマンティック色で自動的に得られます。

And for when you need a pop, there's a bright palette of system colors that all have variants for the increased contrast accessibility mode as well variants for Dark Mode.
そして、ポップが必要なときには、システムカラーの鮮やかなパレットがあり、すべてにコントラストのアクセシビリティモードのバリエーションとダークモードのバリエーションがあります。

There's also a brand-new set of materials and vibrant content filters with varying levels of transparency so you can create UI that looks great over any content.
また、さまざまなレベルの透明度を備えたまったく新しい一連のマテリアルと鮮やかなコンテンツフィルタもあるため、あらゆるコンテンツに対して優れたUIを作成できます。

And just like semantic colors, these materials support both light and dark variants.
そして、セマンティックカラーと同じように、これらの素材は明暗両方のバリエーションをサポートします。

And they will automatically update based on changes to the UI Kit trait collection.
そしてそれらは自動的にUI Kitトレイトコレクションへの変更に基づいて更新されます。

Adopting semantic colors and adaptive materials will help you provide a unified look that automatically adapts to your environment.
セマンティックカラーとアダプティブマテリアルを採用すると、自動的にあなたの環境に適応する統一された外観を提供するのに役立ちます。

Another component of iOS 13's new look is cards.
iOS 13の新しい外観のもう1つの要素はカードです。

Since the original SDK, the default presentation style on iPhone has covered the full screen.
オリジナルのSDK以来、iPhoneのデフォルトのプレゼンテーションスタイルは全画面をカバーしています。

We're changing that default to a much more fluid card presentation.
私たちはそのデフォルトをもっと流動的なカードプレゼンテーションに変更しています。

Cards provide a visual stack so you can see at a glance that you're in a presentation.
カードは視覚的なスタックを提供するので、自分がプレゼンテーション中であることが一目でわかります。

And even better, they're dismissible with just a single downward swipe.
さらに良いことに、それらは1回の下向きのスワイプだけで却下できます。

[ Applause ]
【拍手】

Yeah.
ええ

Swiping.
スワイプ

We've also updated the Peek and Pop experience.
Peek and Popの経験も更新しました。

It's now quicker and easier to access contextual actions throughout the system.
システム全体で状況依存のアクションにアクセスするのがより迅速かつ簡単になりました。

And they're backed by a brand-new API designed to work across all devices.
そしてそれらは、すべてのデバイスにわたって動作するように設計された真新しいAPIによって支えられています。

So not only are they better than ever on iPhone, but they look great on iPad as well.
そのため、iPhone上でこれまで以上に優れているだけでなく、iPad上でも見栄えがよくなります。

And when you bring your iPad app to macOS, they'll look great there to.
そして、あなたがあなたのiPadアプリをmacOSに持ってきたとき、彼らはそこに素晴らしく見えるでしょう。

[ Applause ]
【拍手】

Yeah.
ええ

While we were going through the system, making all those thoughtful refinements, we started thinking about symbols.
私たちがシステムを見ていて、それらすべてを思慮深く洗練させながら、私たちはシンボルについて考え始めました。

Most apps use symbols.
ほとんどのアプリはシンボルを使います。

They are a really useful way to convey information.
それらは情報を伝達するための本当に便利な方法です。

And symbols are very often used with text.
そして、シンボルはテキストと共に非常によく使われます。

But text has some great properties that in iOS 12 our symbols just didn't have.
しかし、テキストには、iOS 12では私たちのシンボルにはなかった優れた特性がいくつかあります。

So as you can see here, the text is scaling nicely as the dynamic type size increases, but the symbols stayed the same.
あなたがここで見ることができるように、テキストは動的な型サイズが増加するにつれてうまく拡大しています、しかしシンボルは同じままでした。

Ideally, we'd want the symbols to scale along with the text.
理想的には、シンボルをテキストに合わせて拡大縮小します。

So we created SF Symbols.
そこで私たちはSFシンボルを作りました。

SF Symbols have all the expressiveness and behavior of a font but packaged up as a UI image so they're really easy to use in your apps.
SFシンボルはフォントの表現力と振る舞いをすべて備えていますが、UIイメージとしてパッケージ化されているので、アプリでは非常に使いやすくなっています。

iOS 13 includes an absolutely massive catalog of over 1,500 SF Symbols for you to use.
iOS 13には、1,500以上のSFシンボルのカタログがあります。

And they're easily searchable right within Xcode and using standalone SF Symbols app on your Mac.
そしてそれらはXcode内で、そしてあなたのMac上のスタンドアロンのSFシンボルアプリを使って簡単に検索することができます。

[ Applause ]
【拍手】

Symbols.
シンボル

[Laughs]
 [笑い]

So now you can see the symbols scale along with the text for better legibility and a more consistent layout at larger sizes.
これで、シンボルがテキストとともに拡大縮小され、読みやすくなり、サイズが大きくなってもレイアウトがより一貫したものになります。

And because they behave just like a font, they're available in all of these weights as well.
そして、それらはフォントのように振る舞うので、これらすべてのウェイトで利用可能です。

[ Applause ]
【拍手】

All of this just scratches the surface of what's available in iOS 13.
これらすべては、iOS 13で利用可能なものの表面を傷つけているだけです。

There's a new share sheet API to let apps have recipient suggestions.
アプリに受信者の提案を許可するための新しい共有シートAPIがあります。

A new compositional layout API to make collection views easier to work with than ever.
コレクションビューをこれまで以上に使いやすくするための新しい構成レイアウトAPI。

And a screenshot enhancement so apps can provide full page views of long content.
スクリーンショットの機能強化により、アプリは長いコンテンツの全ページビューを提供できます。

And so much more.
そしてそんなに多く。

And in addition to all of that, we really wanted to bring iOS forward this year.
そして、これらすべてに加えて、今年はiOSをさらに進化させたいと考えました。

So we gave it its own operating system complete with major enhancements to multitasking, a new PencilKit framework and a whole suite of productivity gestures.
そのため、マルチタスク処理、PencilKitの新しいフレームワーク、そして一連の生産性向上のジェスチャを大幅に強化した独自のオペレーティングシステムを提供しました。

Let's start with multitasking.
マルチタスクから始めましょう。

At iPadOS, your app can be open in multiple spaces at the same time, as well as in the slide-over stack, and display different content in each space.
iPadOSでは、スライドオーバースタックだけでなく、同時に複数のスペースでアプリを開くことができ、各スペースに異なるコンテンツを表示できます。

To enable this, we're introducing a new UI window scene API.
これを可能にするために、我々は新しいUIウィンドウシーンAPIを導入しています。

Each window scene represents a single instance of your app's UI.
各ウィンドウシーンは、アプリのUIの単一のインスタンスを表します。

Prior to iPadOS, your app delegate was responsible for both its process and UI lifecycle.
iPadOSより前は、あなたのアプリデリゲートはそのプロセスとUIライフサイクルの両方を担当していました。

With window scene, we're splitting out the UI portion of that into a new scene delegate object so it can be managed independently.
ウィンドウシーンでは、そのUI部分を新しいシーンデリゲートオブジェクトに分割して、独立して管理できるようにします。

And since they're completely independent, your app can now manage multiple at the same time.
また、これらは完全に独立しているため、アプリは同時に複数を管理できます。

Your users can even use drag and drop to allow individual items from your apps such as a single window or message to be opened in a brand-new window scene.
ユーザーはドラッグアンドドロップを使用して、単一のウィンドウやメッセージなど、アプリの個々のアイテムを新しいウィンドウシーンで開くこともできます。

With this new capability, it's really important that your users can resume whatever they were doing in any scene at any time.
この新しい機能を使用すると、ユーザーはいつでもあらゆるシーンで行っていたことを再開できることが非常に重要です。

To make this easy, we've built a new state restoration system based on NSUserActivity.
これを簡単にするために、NSUserActivityに基づく新しい状態復元システムを構築しました。

You're probably already familiar with this versatile API.
あなたはおそらくすでにこの多用途のAPIに精通しているでしょう。

It's used for handoff, search, indexing, Siri, and now for window scene state restoration.
これは、ハンドオフ、検索、インデックス作成、Siri、そして今ではウィンドウシーンの状態の復元に使用されます。

One of the things that really sets -- you can clap, it's fine.
本当に設定することの一つ - あなたは拍手することができます、それは結構です。

[ Applause ]
【拍手】

One of the things that really sets iPads apart is Apple Pencil.
iPadを際立たせるものの1つがApple Pencilです。

We're introducing PencilKit which allows you to easily add smooth low-latency drawing to your apps.
私たちはあなたがあなたのアプリにスムーズで低レイテンシの描画を簡単に追加することを可能にするPencilKitを導入しています。

This is the same engine used in Apple apps like Notes, Markup and Screenshots.
これは、ノート、マークアップ、スクリーンショットなどのアップルのアプリで使用されているものと同じエンジンです。

So you get all of those same features and tools right in your apps.
それで、あなたはあなたのアプリでまさにそれらの同じ機能とツールの全てを手に入れます。

You can even use the canvas and palette functionality separately and just pick and choose which pieces make sense for your use case.
キャンバスとパレットの機能を別々に使用して、ユースケースに適したピースを選択して選択することもできます。

Finally, let's talk about productivity gestures.
最後に、生産性のしぐさについて話しましょう。

We've made text selection much easier.
テキストの選択がずっと簡単になりました。

You can now just drag your finger along text to select it.
テキストを指でドラッグして選択できます。

Text views and web views are automatically updated with this new selection gesture.
テキストビューとWebビューは、この新しい選択ジェスチャで自動的に更新されます。

And there are new three-finger gestures for undo and redo.
また、元に戻すとやり直すための新しい3本指ジェスチャがあります。

Swipe three fingers left for undo and right for redo.
元に戻すには3本の指を左に、やり直しには右の指をスワイプします。

These new gestures use the existing NSUndoManager so you don't have to do anything at all to adopt.
これらの新しいジェスチャーは既存のNSUndoManagerを使用するので、採用するために何もする必要はありません。

If you'd like easy text selection outside of text or web views, or if your app already uses three-finger gestures and you have a conflict, you can use the UITexInteraction API to fix up those issues.
テキストビューやWebビューの外で簡単にテキストを選択したい場合、またはアプリケーションで既に3本指のジェスチャを使用していて競合がある場合は、UITexInteraction APIを使用してこれらの問題を解決できます。

And for scroll views, you can now drag the scroll indicator to jump directly to a location in the scroll view.
スクロールビューの場合は、スクロールインジケータをドラッグしてスクロールビュー内の場所に直接ジャンプできます。

To enable this behavior, just turn on Show Scroll Indicators.
この振る舞いを有効にするには、単にShow Scroll Indicatorsをオンにします。

For this one it's really important that your scrolling is performant as we might have to load all of the cells in a frame at the same time.
このためには、フレーム内のすべてのセルを同時にロードする必要がある可能性があるため、スクロールが効果的であることが本当に重要です。

We think our users are going to love the powerful new things iPadOS gives them, and we cannot wait to see what you do with it.
私達は私達のユーザーがiPadOSが彼らに与える強力で新しいものを好きになるだろうと思っています、そして私達はあなたがそれをどうするか見るのを待つことができません。

So I'd like to welcome Sebastien back to the stage.
それで、私はSebastienが舞台に戻ってくるのを歓迎したいです。

[ Applause ]
【拍手】

>> Thank you, Cindy.
>>ありがとう、シンディ。

Now as you've seen, each of our platforms has incredible new features that refine the experience that each offers and gives them great new capabilities.
これまで見てきたように、当社の各プラットフォームには、それぞれが提供するエクスペリエンスを洗練させ、優れた新機能を提供する、驚くべき新機能があります。

And across all of our platforms we build a range of technologies that are designed to give your apps a huge head start so that you can build the latest technologies right into your app.
そして、私たちのすべてのプラットフォームで、最新のテクノロジをアプリケーションに組み込むことができるように、あなたのアプリケーションに大きな先駆けを与えるように設計された一連のテクノロジを構築しています。

There are a few of these that we'd like to focus on this afternoon and they cover a pretty wide range of capabilities from how we open our platforms and apps to all users to how we combine the virtual and real-world with augmented reality.
今日の午後に焦点を当てたいものがいくつかあります。それらは、私たちがプラットフォームやアプリを開く方法からすべてのユーザーに至るまで、仮想および実世界を拡張現実と組み合わせる方法まで、かなり広い範囲の機能をカバーします。

And so we start with accessibility, and to do that I'd like to welcome Eric Seymour on stage.
それで私たちはアクセシビリティから始め、それを行うために私はステージ上でEric Seymourを歓迎したいと思います。

Eric?
エリック？

[ Applause ]
【拍手】

>> Thank you, Sebastien.
>>ありがとう、Sebastien。

So we all know that technology plays a powerful role in people's lives.
だから私たちは皆、テクノロジーが人々の生活の中で強力な役割を果たすことを知っています。

But this is especially true for people with disabilities.
しかし、これは障害を持つ人々に特に当てはまります。

Technology can be instrumental in fostering independence, employment and empowerment.
テクノロジーは、自立、雇用、そしてエンパワーメントを促進するのに役立ちます。

At Apple, we're guided by a few key principles for accessibility and it begins with accessibility being built in.
アップルでは、​​私たちはアクセシビリティのためのいくつかの重要な原則に導かれ、それはアクセシビリティが組み込まれていることから始まります。

People should be able to use our products out of the box, and that includes people of all abilities.
人々は箱から出してすぐに私たちの製品を使うことができるはずです、そしてそれはすべての能力の人々を含みます。

Accessibility should be comprehensive.
アクセシビリティは包括的であるべきです。

People should have access to the whole platform, every corner of the OS, every corner of your apps.
人々はプラットフォーム全体、OSの隅々、アプリケーションの隅々までアクセスできるはずです。

And perhaps most important, we want to surprise and delight all users regardless of ability.
そしておそらく最も重要なのは、能力に関係なくすべてのユーザーを驚かせて喜ばせたいということです。

And so this is more than just about fixing accessibility bugs.
だからこれは単にアクセシビリティのバグを修正することだけではありません。

This is about using your features with accessibility and striving for an experience that's great, that's just as inspired as your original design.
これはあなたの機能をアクセシビリティと一緒に使い、素晴らしい経験を目指して努力することです。それはあなたのオリジナルのデザインと同じくらいインスピレーションを得たものです。

When we think about accessibility, we're really talking about a broad continuum of abilities.
アクセシビリティについて考えるとき、私たちは本当に幅広い能力の連続について話しています。

Hearing, vision, physical, learning.
聴覚、視覚、身体、学習

And within each of these areas, we're focused on different conditions.
そして、これらの分野のそれぞれにおいて、私たちはさまざまな条件に焦点を当てています。

So for example, for vision, we of course have Voiceover, our screen reader for people who can't see the screen.
そのため、たとえばビジョンのために、私たちはもちろんスクリーンを見ることができない人のための私たちのスクリーンリーダーVoiceoverを持っています。

But we also have over a dozen vision-related features from zoom to large text.
しかし、ズームから大きなテキストまで、10を超えるビジョン関連の機能もあります。

And when we take this approach and we apply it to that broad continuum of abilities, we're talking about dozens of accessibility features.
そして私たちがこのアプローチをとり、それをその幅広い連続した能力に適用するとき、私たちは何十ものアクセシビリティ機能について話しています。

And it really underscores the notion that accessibility is for everyone.
そしてそれは、アクセシビリティがすべての人にとってのものであるという概念を本当に強調しています。

Probably most of you use at least one accessibility feature.
おそらくあなたのほとんどは少なくとも1つのユーザー補助機能を使用しています。

And if you don't already, there's a good chance you will eventually.
そして、あなたがまだしていないのであれば、結局あなたがそうする可能性が高いです。

This year we're introducing several new accessibility features and enhancements, and today I'm going to talk about two, starting with discoverability.
今年は、いくつかの新しいアクセシビリティ機能と機能強化を紹介します。今日は、発見可能性から始めて、2つについて説明します。

In the spirit of accessibility being for everyone, we wanted to make it easier to find.
アクセシビリティというのはすべての人のためにあるという精神のもとに、見つけやすくするためのものでした。

And so to that end we've added accessibility to iOS Quick Start, making the out-of-box experience even more accessible.
そしてそのために、iOSクイックスタートにアクセシビリティを追加して、すぐに使えるエクスペリエンスをさらにアクセスしやすくしました。

Also we've moved accessibility to the top level of settings.
また、ユーザー補助機能を最上位の設定に移動しました。

[ Applause ]
【拍手】

And we've reorganized it to make things easier to find.
そして、私たちは物事を見つけやすくするためにそれを再編成しました。

We think it's going to go a long way to help people discover and use these great features.
私たちは、人々がこれらのすばらしい機能を見つけて使用するのを助けるために長い道のりを行くだろうと思います。

Now let's talk about voice control, right?
それでは、音声制御について説明しましょう。

We saw this this morning during the keynote.
私たちは今朝基調講演の間にこれを見ました。

Voice control is this full voice experience from macOS, iOS and iPadOS and we think it's going to be really helpful for people with physical challenges.
音声制御は、macOS、iOS、およびiPadOSによるこの完全な音声エクスペリエンスであり、身体的な問題を抱えている人々にとっては本当に役立つと考えています。

Voice control provides comprehensive platform access.
音声制御は包括的なプラットフォームアクセスを提供します。

You can speak to items by name.
あなたは名前でアイテムに話すことができます。

You can refer to items by number.
番号でアイテムを参照できます。

You can even speak to regions of the screen using a grid.
あなたはグリッドを使ってスクリーンの領域と話すことさえできます。

Voice control has got great text editing.
音声制御は素晴らしいテキスト編集を得ました。

So of course I can dictate text but I can also make selections and corrections using only my voice.
だから私はもちろんテキストを口述することができますが私は私の声だけを使って選択や修正をすることもできます。

And it also has awareness.
そしてそれはまた意識を持っています。

So effectively even when I'm dictating text, it hears commands and it doesn't make me manage that distinction.
だから私がテキストを口述している時でさえ効果的にそれは命令を聞きます、そしてそれは私がその区別を管理するようにしません。

I can just talk to it.
私はそれについて話すことができます。

And using the true depth camera, if I look away, it knows that it can ignore me.
そして本当の深さのカメラを使って、私が目をそらすならば、それは私を無視することができることを知っています。

Voice control's got great spoken gestures so of course I can do simple things like taps and swipes.
音声コントロールは素晴らしい音声ジェスチャーを持っているので、もちろんタップやスワイプのような簡単なことができます。

But I can also pre-record more complex gestures that I might want to use in an app or a game, like this rotate gesture.
しかし、この回転ジェスチャーのように、アプリやゲームで使用したいと思うより複雑なジェスチャーを事前に記録することもできます。

And of course voice control speech recognition runs fully on device.
そしてもちろん、音声制御音声認識は完全にデバイス上で動作します。

And so now I'd like to show you voice control in action.
そして今、私はあなたに音声制御の動作を見せたいのです。

[ Applause ]
【拍手】

And for this demo I'm going to be talking to my iPhone.
そしてこのデモのために私は私のiPhoneと話をするつもりです。

Open messages.
メッセージを開く

Hey Chris, let's grab dinner tonight.
こんにちはクリス、今夜の夕食をつかみましょう。

I'm thinking pizza.
私はピザを考えています。

Pizza emoji.
ピザ絵文字。

Change tonight to this weekend.
今週末に今週を変える。

Tap send.
送信をタップします。

Undo that.
元に戻します。

Tap send.
送信をタップします。

[ Laughter ]
[ 笑い ]

Undo that.
元に戻します。

Tap send.
送信をタップします。

[ Applause ]
【拍手】

Open Maps.
マップを開きます。

Tap search field.
検索欄をタップします。

San Pedro Square.
サンペドロ広場。

Show numbers.
数字を表示

Five.
五。

Show grid continuously.
継続的にグリッドを表示します。

15.
 15。

Zoom at one.
一つにズームしてください。

Repeat four times.
4回繰り返します。

[ Applause ]
【拍手】

Swipe up at 27.
27で上にスワイプします。

Hide grid.
グリッドを隠す

Tap share.
共有をタップします。

Tap Chris Adams.
Chris Adamsをタップします。

Lots of options around here, period.
この辺りにはたくさんのオプションがあります。

See you later.
じゃあまたね。

Peace emoji.
平和絵文字。

Ah, look at that.
ああ、それを見てください。

Undo that.
元に戻します。

Peace emoji.
平和絵文字。

Tap send.
送信をタップします。

[ Laughter ]
[ 笑い ]

Undo that.
元に戻します。

Tap send.
送信をタップします。

[ Applause ]
【拍手】

Go home.
家に帰りなさい。

Go to sleep.
寝る。

Okay.
はい。

So that's voice control.
これが音声制御です。

Now -- [ Applause ]
今 -  [拍手]

Now we can also use voice control as developers to test the accessibility of our apps.
開発者として音声制御を使用して、アプリのアクセシビリティをテストすることもできます。

And so let's do that now with the travel app that you saw earlier.
それでは、先ほど見たことのある旅行アプリを使って、今それをやりましょう。

Wake up.
目を覚ます。

Open Travel.
オープントラベル

Tap San Francisco.
サンフランシスコをタップします。

Tap San Francisco.
サンフランシスコをタップします。

Show names.
名前を表示する

All right, here's the problem.
大丈夫、これが問題です。

So I'm trying to tap on San Francisco, this element, but it doesn't have a good accessibility label yet and it's a really common problem.
それで、私はサンフランシスコ、この要素を利用しようとしています、しかしそれはまだ良いアクセシビリティラベルを持っていません、そしてそれは本当に一般的な問題です。

It means I can't speak to this element with voice control, and even worse, if I couldn't see the screen and Voiceover were reading this to me, I'd be completely out of luck, stopped in my tracks.
それは私が音声制御でこの要素と話すことができないことを意味します、そしてさらに悪いことに、スクリーンが見えずVoiceoverが私にこれを読んでいないならば、私は完全に運が悪く、私のトラックに止まります。

I would not be able to use this app.
私はこのアプリを使うことができないでしょう。

So fortunately these things are pretty easy to fix.
とても幸いなことに、これらのことは修正するのがとても簡単です。

And so let's talk about what you can do to make your apps more accessible.
それでは、アプリをより使いやすくするためにできることについて説明しましょう。

The good news is, most accessibility features just work.
幸いなことに、アクセシビリティ機能のほとんどは機能します。

But some of them, indeed the most transformative features like Voice Control and Switch Control and Voiceover, they need your support.
しかし、そのうちのいくつかは、確かにVoice ControlやSwitch Control、Voiceoverのような最も変革的な機能であり、あなたのサポートが必要です。

And so here's what you can do.
そして、これがあなたができることです。

First, do what we just did.
まず、今行ったことを行います。

Just try it.
やってみなよ。

Use your apps with accessibility features.
ユーザー補助機能付きのアプリを使用してください。

You might actually be surprised at what already works.
あなたは実際にすでにうまくいっていることに驚くかもしれません。

But more importantly, you're going to gain valuable insight into how some users actually experience your app.
しかし、もっと重要なのは、何人かのユーザーが実際にアプリを体験する方法について貴重な洞察を得ることです。

And you're probably going to want to make some changes.
そして、おそらくいくつかの変更を加えたいと思うでしょう。

Next, use the tools.
次に、ツールを使ってください。

Xcode's got great built-in accessibility support for developers.
Xcodeは開発者向けの優れた組み込みのアクセシビリティサポートを持っています。

You can edit accessibility properties right in the Xcode inspector.
アクセシビリティプロパティはXcodeインスペクタで直接編集できます。

And with new Environment Overrides, you can preview visual accessibility accommodations during your development lifecycle right in your app.
また、新しいEnvironment Overridesを使用すると、開発ライフサイクル中に視覚的なユーザー補助機能をアプリ内でプレビューできます。

It's really cool.
本当にかっこいいです。

Finally, implement the Accessibility API.
最後に、アクセシビリティAPIを実装します。

It's the best way to ensure an accessible experience.
アクセスしやすいエクスペリエンスを確保するための最善の方法です。

It's the essential way.
それは本質的な方法です。

Doing this well is like putting out a welcome mat to your app for users of all abilities.
これをうまくやることは、あらゆる能力を持つユーザーのためにあなたのアプリにウェルカムマットを出すことのようなものです。

It's how Voiceover and Switch Control and the rest talk to your app to offer an adapted experience.
VoiceoverとSwitch Control、そしてそれ以外があなたのアプリと会話して適応した体験を提供するのです。

The Accessibility APIs work on all platform, and while they're easy to implement, they're super powerful.
アクセシビリティAPIはすべてのプラットフォームで機能し、実装は簡単ですが、非常に強力です。

So even the most sophisticated apps and experiences can be made fully accessible.
そのため、最も洗練されたアプリやエクスペリエンスでも完全にアクセス可能にすることができます。

And of course, SwiftUI has great accessibility support built right in.
そしてもちろん、SwiftUIには優れたアクセシビリティサポートが組み込まれています。

And so that's our accessibility update today.
そして、それが今日の私たちのアクセシビリティアップデートです。

Now another thing we care deeply about at Apple is privacy.
今私達がアップルで深く気にしているもう一つのことはプライバシーです。

And so to tell you more about that, I'd like to hand things over to Katie.
そしてそれについてもっとお話しするために、Katieに物を渡したいと思います。

Thanks very much.
どうもありがとう。

[ Applause ]
【拍手】

>> Thanks, Eric.
>>ありがとう、エリック。

Privacy is a topic that isn't going away.
プライバシーは消えないトピックです。

And it's something that everyone needs to pay attention to.
そしてそれは皆が注意を払う必要があるということです。

It's something you have to design in from the beginning and it shapes how your product works.
それはあなたが最初からデザインしなければならない何かであり、そしてそれはあなたの製品がどのように働くかを形作る。

When you're designing a new feature, here are a few steps that you can take to design for privacy.
新しい機能を設計するときは、プライバシーを考慮して設計するためのいくつかの手順を次に示します。

Process on the user's device.
ユーザーのデバイス上で処理します。

Wherever you can keep user data on-device, do it.
ユーザーデータをデバイスに保存できる場所であれば、いつでも実行できます。

And this helps you to collect as little data as you can.
そしてこれはあなたができる限り少ないデータを集めるのを助けます。

If you don't have the data, it can't be abused or stolen.
あなたがデータを持っていなければ、それは悪用されたり盗まれたりすることはできません。

Ask first.
最初に聞いてください。

Ask permission from your user for the data and how you plan to use it.
データとその使用方法について、ユーザーから許可を得てください。

And if you do collect data, use random identifiers.
また、データを収集する場合は、ランダムな識別子を使用してください。

And scope them down from an account to a device, to a session where possible.
また、アカウントからデバイス、可能であればセッションまでを範囲とします。

And encrypt to keep your users' data secure.
ユーザーのデータを安全に保つために暗号化します。

Applying these principles in your design process will help you build great features and great privacy.
設計プロセスでこれらの原則を適用すると、優れた機能と優れたプライバシーを構築するのに役立ちます。

I want to talk about two areas where we've made it easier for you to take these steps.
私たちはあなたがこれらのステップを踏むことをより簡単にした2つの分野について話したいと思います。

First, location.
まず、場所です。

Where you go can reveal a lot about your life.
あなたがどこへ行くかはあなたの人生について多くを明らかにすることができます。

Where you live, where you work, what doctor's office you might go to, or how often you're hitting the gym versus maybe the bar.
あなたが住んでいる場所、あなたが仕事をしている場所、あなたが行くかもしれない医者の診療所、あるいはあなたがジムにぶつかる頻度対バーかもしれません。

Because of this, some users are hesitant to share location with you and your apps.
このため、何人かのユーザーはあなたとあなたのアプリと位置情報を共有することに躊躇しています。

So they might miss out on some of your key features.
だから彼らはあなたの重要な機能のいくつかを見逃してしまうかもしれません。

So this year, we're adding a new option: Allow Once.
そのため、今年は新しいオプションを追加します。[Allow Once]です。

This provides location access for just that session and will ask the user again next time.
これはちょうどそのセッションのための位置アクセスを提供し、次回ユーザーにもう一度尋ねます。

But let's say your app is even better with Always Allow Location permission.
ただし、常に場所を許可するアクセス許可を使用すると、アプリはさらに優れたものになります。

Here's how this will now work.
これが今どのように動作するかです。

First the user needs to select While In Use.
最初にユーザーは「使用中」を選択する必要があります。

Then you request location while your app is in the background.
その後、アプリがバックグラウンドにある間に位置情報を要求します。

Then the user will be presented with an alert, letting them know that you're requesting location in the background.
その後、ユーザーに警告が表示され、バックグラウンドで位置情報を要求していることをユーザーに知らせます。

If they change to Always Allow, you'll have background location access moving forward.
[常時許可]に変更した場合は、バックグラウンドでの位置情報へのアクセス権があります。

Finally, we're giving users more transparency into how their location is being accessed.
最後に、ユーザーの所在地へのアクセス方法の透明性を高めています。

For all apps with background location permission, from time to time we'll show them where your app accessed their location.
バックグラウンドの場所の許可を持つすべてのアプリについて、時々、アプリが場所にアクセスした場所を表示します。

[ Applause ]
【拍手】

With these changes to permissions, users will feel more comfortable in how they're sharing location with you.
これらのアクセス許可の変更により、ユーザーは自分と位置情報を共有している方法がより快適になります。

Now, let's talk about login.
それでは、ログインについて話しましょう。

We've all seen or maybe implemented buttons like these.
私達はみんなこれらのようなボタンを見たか、あるいは実装したかもしれません。

And they can be really convenient, but they can come at the cost of your user's privacy.
そしてそれらは本当に便利になることができます、しかしそれらはあなたのユーザーのプライバシーを犠牲にして来ることができます。

They also might share more information about your company's business than you really want to be disclosing.
彼らはまたあなたが本当に開示したいと思うよりもあなたの会社の事業についてのより多くの情報を共有するかもしれません。

So we want to offer a better option.
だから我々はより良​​い選択肢を提供したいと思います。

And it's called Sign In With Apple.
そしてそれはAppleとのサインインと呼ばれます。

[ Applause ]
【拍手】

It offers fast, easy sign-in without all the tracking.
すべての追跡がなくても、すばやく簡単にサインインできます。

This isn't just about privacy for our users, but also for your company.
これは私達のユーザーのためだけでなくあなたの会社のためのプライバシーについてだけではありません。

It's not our business to know how users engage with your app, so Apple simply won't track that.
ユーザーがアプリとどのように関わっているかを知るのは私たちの事業ではないので、Appleは単にそれを追跡しません。

[ Applause ]
【拍手】

It's easy to add a Sign In With Apple button to your app with a simple API.
シンプルなAPIを使用して、Appleにサインインボタンをアプリに追加するのは簡単です。

Users can set up an account and sign into your app with a tap and a quick Face ID.
ユーザーはアカウントを設定し、タップとクイックフェイスIDを使ってアプリにサインインできます。

So why is this great for all of you?
それで、なぜこれはあなた全員にとって素晴らしいのですか？

First off, more trust and less friction equals more engaged users.
第一に、信頼性が高まり摩擦が少ないということは、より多くのユーザーが関与することです。

Sign In With Apple can shorten the distance between a user considering your application and really embracing it.
アップルではあなたのアプリケーションを検討して実際にそれを採用しているユーザーとの距離を縮めることができます。

Second, verify email addresses.
次に、メールアドレスを確認します。

Apple has already done the work of verifying email addresses for you.
AppleはすでにあなたのためにEメールアドレスを確認する仕事をしました。

[ Applause ]
【拍手】

And we're removing the incentive for users to share made-up email addresses by offering a private email relay service.
また、プライベートのEメールリレーサービスを提供することで、ユーザーがメークアップEメールアドレスを共有する動機を取り除きます。

So even if a user chooses to hide their email address when setting up an account, your email will arrive in their verified account, their verified inbox.
そのため、アカウントの設定時にユーザーが自分の電子メールアドレスを非表示にすることを選択したとしても、あなたの電子メールは確認済みのアカウント、確認済みの受信トレイに届きます。

And then there's security.
そしてセキュリティがあります。

With Sign Into Apple, you don't need to deal with storing passwords or password reset issues.
Appleにサインインすれば、パスワードの保存やパスワードリセットの問題に対処する必要はありません。

And every single account is protected with two-factor authentication.
また、すべてのアカウントは2要素認証で保護されています。

[ Applause ]
【拍手】

This can really improve your security.
これは本当にあなたのセキュリティを向上させることができます。

We've also integrated some interesting innovations around anti-fraud.
私たちはまた、不正防止に関するいくつかの興味深い革新を統合しました。

We all know that along with some real users, sometimes you get some not so real users.
私たちは皆、何人かの本当のユーザーと一緒に、時々あなたはそれほど実際ではないユーザーを得ることを知っています。

Nobody wants bots or farmed accounts.
誰もボットや農場のアカウントを望んでいません。

And we work hard to filter them out of our systems.
そして私達は私達のシステムからそれらを除外するために一生懸命働きます。

And we want to help you do the same.
そして、私たちはあなたが同じことをするのを助けたいです。

So we built what we call a real user indicator.
そこで、私たちは本当のユーザーインディケータと呼ぶものを作りました。

It can tell you if an incoming account is a real user or if you might want to do some additional verification.
入ってくるアカウントが本物のユーザーなのか、それとも追加の確認をしたいのかを教えてくれます。

So how does this work?
それで、これはどのように機能しますか？

First off, the whole system is built from the ground up to maintain user privacy.
まず、システム全体がユーザーのプライバシーを守るためにゼロから構築されます。

It uses on-device intelligence to determine if the originating device is behaving in a normal way.
発信元デバイスが通常の方法で動作しているかどうかを判断するために、オンデバイスインテリジェンスを使用します。

The device generates a value without sharing any specifics with Apple.
デバイスは、アップルと詳細を共有せずに値を生成します。

This is combined with select account information and then boiled down into a single value that's shared with your app at account setup time.
これは選択したアカウント情報と組み合わされ、アカウント設定時にアプリと共有される単一の値にまとめられます。

Then depending on the value that you receive, you can be confident that your new user is a real user or get a signal that you might want to take a second look.
それから、あなたが受け取る価値次第で、あなたはあなたの新しいユーザーが本当のユーザーであることを確信するか、またはあなたが見直すことを望むかもしれないというシグナルを得ることができます。

And all of this comes with great cross-platform support.
そしてこれらすべてに、優れたクロスプラットフォームサポートが付属しています。

It's available on iOS, iPadOS, macOS, watchOS, tvOS and it even works on the web.
iOS、iPadOS、macOS、watchOS、tvOSで利用可能で、Web上でも動作します。

So it can work on Android and Windows devices.
だからそれはAndroidとWindowsデバイス上で動作することができます。

[ Applause ]
【拍手】

So there you go.
だからそこに行きます。

A super-fast and easy way to engage new users, two-factor authentication and anti-fraud built in.
新しいユーザー、2要素認証、および不正防止機能が組み込まれた超高速で簡単な方法。

You can implement it virtually anywhere, and most importantly, it respects everyone's privacy.
あなたは事実上どこにでもそれを実装することができます、そして最も重要なことに、それは皆のプライバシーを尊重します。

So this is a solution both you and your users can trust.
だからこれはあなたとあなたのユーザーの両方が信頼できる解決策です。

We've already had a number of developers working with us and we're excited to see many more of you adopt.
私たちはすでに多くの開発者と協力していますし、もっと多くの開発者が採用するのを楽しみにしています。

So that's Sign In With Apple.
これがAppleのサインインです。

[ Applause ]
【拍手】

As I mentioned earlier, a great way to preserve user privacy is to work with the users' data on-device.
前述したように、ユーザーのプライバシーを保護するための優れた方法は、デバイス上のユーザーのデータを操作することです。

And we've built some great technologies for doing just that.
そして、それを実現するための優れたテクノロジをいくつか構築しました。

To tell you more about machine learning, I'd like to hand it over to Bill.
機械学習についてさらに詳しく説明するために、Billに渡します。

[ Applause ]
【拍手】

>> Thank you, Katie.
>>ありがとう、ケイティ。

[ Applause ]
【拍手】

Machine learning is a key technology for so many of the experiences in your apps.
機械学習は、アプリのさまざまなエクスペリエンスにとって重要なテクノロジです。

And at Apple, we use on-device machine learning to power features from stunning camera and photos capabilities to AR Kit and more.
そしてアップルでは、​​すばらしいカメラや写真の機能からAR Kitなどの機能まで、オンデバイスの機械学習を使用しています。

And we can do this because of our cutting-edge silicon.
最先端のシリコンのおかげでこれが可能になります。

With powerful CPUs, GPUs and dedicated ML processors like the Neural Engine, we can deliver incredible real-time experiences.
Neural Engineのような強力なCPU、GPU、および専用MLプロセッサを使用すると、信じられないほどのリアルタイムエクスペリエンスを実現できます。

The Neural Engine is optimized to accelerate convolutional neural networks with multi-precision support and a Smart Compute system.
Neural Engineは、多精度サポートとSmart Computeシステムを使用して畳み込みニューラルネットワークを高速化するように最適化されています。

What does that mean?
どういう意味ですか？

It means it's an absolute beast.
それは絶対的な獣だということです。

In fact, the Neural Engine is capable of up to 5 trillion operations per second.
実際、Neural Engineは1秒間に最大5兆回の操作が可能です。

Best of all, we've built our machine learning APIs on top of this so that your apps can take full advantage of this blazing performance.
何よりも、私たちはあなたのアプリがこの素晴らしいパフォーマンスを最大限に活用できるように、これに加えて私たちの機械学習APIを構築しました。

And we have some great updates, starting with our out-of-the-box APIs like Vision, Natural Language, and Speech.
また、Vision、Natural Language、Speechなどのすぐに使えるAPIから始めて、素晴らしい更新がいくつかあります。

Today these APIs deliver rich features such as face detection, object tracking and named entity recognition.
今日、これらのAPIは、顔検出、オブジェクト追跡、名前付きエンティティ認識などの豊富な機能を提供します。

And this year, we're adding even more.
そして今年、私たちはさらに追加しています。

Let's have a look at a few of these, starting with image saliency which gives you a heatmap for an image, highlighting important objects and where users are likely to focus their attention.
重要なオブジェクトを強調し、ユーザーが注目を集める可能性がある部分を強調して、画像の重要性を明確にすることから始めて、これらのいくつかを見てみましょう。

We use this today in photos to help intelligently crop images as part of the curation experience.
私たちは今日キュレーション体験の一部として画像を知的にトリミングするのを助けるために写真でこれを使います。

We're also releasing text recognition where you can search text from images like posters, signs and documents.
ポスター、サイン、文書などの画像からテキストを検索できるテキスト認識機能もリリースしました。

[ Applause ]
【拍手】

And take advantage of the document camera capability we use in Notes.
また、Notesで使用する書画カメラ機能を活用してください。

For Natural Language, you can make use of word embeddings which help to identify words or sentences with similar meanings.
自然言語の場合は、単語や文章を識別するのに役立つ単語の埋め込みを利用できます。

We use this today for search in photos so that if you search for an unknown term like musician, we can suggest alternatives like entertainer or singer.
あなたがミュージシャンのような未知の用語を検索する場合、私たちは芸能人や歌手のような代替案を提案できるように、私たちは今日写真の検索にこれを使います。

And this year, our Speech API is now on-device and works on iPhone, iPad and Mac with support for 10 languages.
そして今年、私たちのSpeech APIは現在デバイス上にあり、iPhone、iPadそしてMac上で動作し10の言語をサポートしています。

[ Applause ]
【拍手】

And with features like Speech Saliency, you can understand the pronunciation, pitch and the cadence of speech.
そして、Speech Saliencyのような機能を使って、発音、ピッチ、そしてスピーチのケイデンスを理解することができます。

Now for those of you who want to go deeper with machine learning, you can make use of Core ML, our on-device technology designed to run machine learning models with high performance and privacy.
機械学習をより深く学びたい方のために、高性能とプライバシーを備えた機械学習モデルを実行するために設計された当社のオンデバイステクノロジであるCore MLを利用することができます。

Today Core ML has great support for many machine learning models, from neural networks to boosted trees and more.
今日のCore MLは、ニューラルネットワークからブーストツリーなど、多くの機械学習モデルをサポートしています。

But as you know, the field of machine learning is constantly evolving.
しかしあなたが知っているように、機械学習の分野は絶えず進化しています。

And so this year we set out to support the most advanced neural networks by adding more layer types than ever before.
そこで今年は、これまで以上に多くのレイヤータイプを追加することで、最先端のニューラルネットワークをサポートすることを目指しました。

In fact, Core ML now supports over 100 model layer types.
実際、Core MLは現在100を超えるモデルレイヤタイプをサポートしています。

This enables you to run some of the most cutting-edge machine learning models on Apple devices.
これにより、アップルデバイスで最先端の機械学習モデルをいくつか実行することができます。

Models like ELMO or WaveNet or some very recently published ones like BERT, bringing breakthrough natural language processing to your apps.
ELMOやWaveNetのようなモデル、あるいはBERTのようなごく最近公開されたモデルはあなたのアプリに画期的な自然言語処理をもたらします。

Now running models like these in your apps is only part of the story.
アプリでこれらのモデルを実行することは、ストーリーの一部に過ぎません。

There are times when you may want to update the models in your apps on-device based on user data.
ユーザーデータに基づいて、デバイス上のアプリのモデルを更新したい場合があります。

We do this today for features like Face ID where a user's appearance may be evolving over time.
フェイスIDのように、ユーザーの外観が時間の経過とともに変化する可能性がある機能のために今日これを行います。

They change their hair, wear a hat.
彼らは髪を変え、帽子をかぶります。

Or for features like our Siri Watch Face where the set of recommendations is constantly evolving to deliver a personalized experience for each user.
または、Siri Watch Faceのように、各ユーザーにパーソナライズされたエクスペリエンスを提供するために一連の推奨事項が絶えず進化している機能のために。

To achieve these experiences, we use on-device personalization.
これらの経験を達成するために、我々はデバイス上のパーソナライゼーションを使用します。

And this year we're bringing that capability to Core ML.
そして今年、私たちはその機能をコアMLにもたらします。

This means you can update the Core ML models in your app with data from individual users.
つまり、個々のユーザーからのデータを使ってアプリ内のCore MLモデルを更新できます。

This creates -- [ Applause ]
これは作成します -  [拍手]

This creates an updated and personalized model for the user.
これにより、ユーザー用に更新されたパーソナライズモデルが作成されます。

With model personalization, your apps can now update models in the background without compromising user privacy.
モデルのパーソナライズにより、アプリはユーザーのプライバシーを損なうことなくバックグラウンドでモデルを更新できるようになりました。

Core ML delivers the most advanced platform for machine learning models, and building Core ML models has never been easier with Create ML, our framework designed to help all of you build models with just a few lines of code.
Core MLは、機械学習モデルのための最も先進的なプラットフォームを提供します。CoreMLは、ほんの数行のコードでモデルを構築できるように設計されたフレームワークです。

And this year we're taking Create ML even further.
そして今年は、さらにCreate MLを採用しています。

It's now a macOS app that lets you build models with zero code right from your Mac.
Macから、コードなしでモデルを構築できるmacOSアプリになりました。

[ Applause ]
【拍手】

You can choose from many different model templates to fit your data.
データに合わせて、さまざまなモデルテンプレートから選択できます。

You can build multiple models with different datasets and define the parameters for each of them.
異なるデータセットを使用して複数のモデルを構築し、それらのモデルごとにパラメータを定義できます。

You get real-time feedback on model training.
モデルトレーニングに関するリアルタイムのフィードバックを得ることができます。

And Create ML supports transfer learning for tasks like image classification or text analysis.
また、Create MLは、画像分類やテキスト分析などのタスクのための転送学習をサポートしています。

This speeds up training since you need very little data and can leverage Apple's optimized and heavily pre-trained models.
必要なデータが非常に少なく、アップルの最適化された高度に事前トレーニングされたモデルを利用できるため、これによってトレーニングがスピードアップします。

And you get to experiment and preview the models.
そして、モデルの実験とプレビューができます。

So for example, you can get predictions for images by using your iPhone's camera with continuity on your Mac.
例えば、あなたはあなたのMac上で継続的にあなたのiPhoneのカメラを使うことによって画像の予測を得ることができます。

Or you can use the microphone on your Mac to test your sound classification model.
または、Macのマイクを使ってサウンド分類モデルをテストすることもできます。

So that's a ton of new stuff and we're super excited to see what you can do with all these awesome new machine learning capabilities.
それで、それは新しいもののトンです、そして、私たちはあなたがこれらすべての素晴らしい新しい機械学習能力で何ができるかを見るのをとても興奮しています。

In fact, we invited a few developers to try out all the new stuff and we've seen some amazing results.
実際、私たちは何人かの開発者を招待してすべての新しいものを試してみました。そして驚くべき結果を見ました。

One in particular was so cool we decided we had to share it with you.
特にクールだったので、私たちはあなたとそれを共有しなければならないと決めました。

So please welcome Ben Harroway from Lumen Digital to give you a preview of his new app NoisyBook.
それで、あなたに彼の新しいアプリNoisyBookのプレビューを与えるためにLumen DigitalからベンHarrowayを歓迎してください。

[ Applause ]
【拍手】

>> Thanks, Bill.
>>ありがとう、ビル。

Hi, everyone, I'm Ben from Lumen Digital and I've been working on a brand-new app, NoisyBook.
こんにちは、みんな、私はLumen DigitalのBenです。私は真新しいアプリNoisyBookに取り組んでいます。

Let me tell you a story.
話をさせてください。

Once upon a time, on a beautiful meadow lived a boy called Jack and his cow Daisy.
むかしむかし、美しい牧草地で、ジャックと彼の牛デイジーという男の子が住んでいました。

Daisy.
デイジー

[ Cow mooing ]
[牛の係留]

A mysterious man gave them some magic beans which grew into a giant beanstalk, high into the clouds.
神秘的な男が彼らにいくつかの魔法の豆を渡し、それが雲の高いところで巨大な豆の木に成長しました。

[ Mystical music ]
[神秘的な音楽]

Okay, I think everybody knows this story.
さて、私は誰もがこの話を知っていると思います。

Let's try something really different.
本当に違うことを試してみましょう。

Suddenly an exploding chicken and his friend the golden tiger [growling]
突然爆発するチキンと彼の友人の黄金の虎[うなる]

jumped into their helicopter [whirring]
彼らのヘリコプターに飛び込んだ[旋風]

and flew into the forest.
そして森に飛び込んだ。

[ Crickets and bird sounds ]
[クリケットと鳥の音]

And of course, guess what?
そしてもちろん、どう思いますか？

They all lived happily ever after.
彼らは皆、その後ずっと幸せに暮らしていました。

[ Music ]
[音楽]

>> Yay.
>>はい。

>> Can you make animal noises you heard in the story?
>>あなたは物語の中で聞いた動物の音を立てることができますか？

>> Okay, we've had some fun.
>>わかりました、私達はある楽しい時を過しました。

Now NoisyBook wants us to repeat some of the animal noises that we heard during the story.
今やNoisyBookは私達が物語の間に聞いた動物の音のいくつかを繰り返すことを私たちに望んでいます。

I think we heard a cow in this story, so let's try this.
私たちはこの話で牛を聞いたと思うので、これを試してみましょう。

Moo.
武。

There he is.
彼がいます。

I really cannot believe I'm standing here making animal noises in front of all of these people.
私がここに立っているのは、これらの人々全員の前で動物の音を立てるとは本当に信じられません。

Mad.
マッド。

But how amazing, the app has used a sound classification model to actually recognize that noise and acknowledge it.
しかし、驚くほど素晴らしいことに、このアプリは実際にそのノイズを認識し、それを認識するために音声分類モデルを使用しました。

You likely also noticed NoisyBook was able to work with both traditional stories and stories straight from our own imaginations.
あなたはまた、NoisyBookが伝統的な物語と私たち自身の想像から直接物語の両方で働くことができたのに気付いたでしょう。

It's super powerful.
超強力です。

And thanks to the new features of speech, sound and Core ML in iOS 13 and Create ML, this is all happening entirely on-device.
そして、iOS 13およびCreate MLのスピーチ、サウンド、およびCore MLの新機能のおかげで、これはすべてデバイス上で行われています。

It's all happening in real time and it's running through a natural language model that I've trained on over 90,000 lines of text.
これはすべてリアルタイムで行われており、私が9万行以上のテキストでトレーニングした自然言語モデルを使用しています。

And thanks to these features, I've been able to take an idea that I've struggled with for around two years and really implement some of these magical new features in just a couple of days.
そしてこれらの機能のおかげで、私は約2年間苦労したという考えを持ち、ほんの2、3日で本当にこれらの魔法の新しい機能のいくつかを実装することができました。

I'm super proud of it and I do hope that you'll remember to check out NoisyBook when it lands on the App Store later this year.
私はそれを非常に誇りに思っています、そして、それが今年遅くにApp Storeに上がるとき、あなたがNoisyBookをチェックアウトするのを忘れないことを願っています。

Thank you.
ありがとうございました。

[ Applause ]
【拍手】

>> Thanks, Ben.
>>ありがとう、ベン。

That was really cool.
それは本当にクールでした。

I know my kids are going to love it.
私の子供たちはそれを愛するつもりです知っています。

Now one of the biggest uses of machine learning at Apple is Siri.
今Appleで機械学習の最大の用途の1つはSiriです。

Siri is by far the world's most popular intelligent assistant with over 500 million monthly active devices, making over 15 billion requests.
Siriは世界で最も人気のあるインテリジェントアシスタントであり、毎月5億を超えるアクティブデバイスを持ち、150億を超える要求を出しています。

These are staggering numbers.
これらは驚くべき数字です。

And Siri works across all of Apple's devices.
そしてSiriはAppleのすべてのデバイスに渡って機能します。

With Siri, your users can interact with your apps in new ways.
Siriを使用すると、ユーザーは新しい方法でアプリと対話できます。

On the go, with Air Pods, hands-free from across the room, or even while in the car.
外出先では、Air Podsを使用すれば、部屋のどこからでも、車の中からでもハンズフリーで使用できます。

And thousands of apps are now integrated with Siri through Siri Shortcuts.
そして何千ものアプリがSiri Shortcutsを通してSiriと統合されています。

We built Siri Shortcuts to allow you to expose the capabilities you already have in your apps with very little work and in a discoverable way for your users.
Siriのショートカットを作成して、あなたがあなたのアプリに既に持っている機能をほんの少しの作業であなたのユーザーのために発見可能な方法で公開できるようにしました。

You can make your shortcuts discoverable using the Add to Siri button, educating your users on how they can use your app with voice.
自分のショートカットを[Siriに追加]ボタンを使用して検出可能にし、ユーザーが音声でアプリを使用する方法についてユーザーを教育することができます。

That matters because voice functionality can otherwise be really hard to discover.
それ以外の点では、音声機能を発見するのは本当に難しいからです。

And we've simplified setup so that the user no longer needs to record a phrase.
また、ユーザーがフレーズを録音する必要がなくなるように設定を簡素化しました。

You suggest a phrase and they add it with a tap.
あなたはフレーズを提案し、彼らはタップでそれを追加します。

[ Applause ]
【拍手】

And the biggest request we had this year was to support parameters in Shortcuts.
そして、今年の最大の要望は、ショートカットのパラメータをサポートすることでした。

So we've made Shortcuts conversational which allows users to interact with your app through questions in Siri.
そこで、Siriで質問を通してユーザーがあなたのアプリと対話することを可能にする会話型のショートカットを作成しました。

So for example, if I'm choosing what to cook, I could run a Shortcut with Pana, my recipes app, and see a list of all my favorites.
たとえば、料理するものを選択した場合は、レシピアプリのPanaでショートカットを実行して、お気に入りのすべてのリストを表示できます。

When I choose from the list, it takes me to the recipe and starts playing.
リストから選ぶと、それはレシピに連れて行かれてプレイを始めます。

And this year the Shortcuts app is built into iOS and iPadOS, which means that every user will have an opportunity to try it out.
そして今年、ショートカットアプリはiOSとiPadOSに組み込まれています。つまり、すべてのユーザーが試してみる機会があります。

And the app is now the home for shortcuts from your apps too.
そして、そのアプリはあなたのアプリからのショートカットの本拠地になりました。

And by popular request, we're adding support for automation.
そして一般的な要求により、自動化のサポートを追加しています。

[ Applause ]
【拍手】

Which allows users to set specific triggers for when to run any shortcut.
これにより、ユーザーはショートカットをいつ実行するかについて特定のトリガーを設定できます。

And there's plenty of options to choose from.
そして、選択肢はたくさんあります。

You can trigger a shortcut based on time of day, when you start a workout on your Apple Watch, when you connect to CarPlay and many more.
Apple Watchでワークアウトを開始したとき、CarPlayなどに接続したときなど、時刻に基づいてショートカットを起動できます。

And the editor now enables full configuration of your app's actions, including the ability to pass information in or out of your action through parameters.
また、エディタを使用して、パラメータを介してアクションの内外に情報を渡す機能など、アプリケーションのアクションを完全に設定できます。

With this, your app's actions can be combined with actions from other apps in multi-step shortcuts.
これにより、アプリのアクションを他のアプリのアクションとマルチステップのショートカットで組み合わせることができます。

Let's say you need to get dinner for the family.
家族のために夕食をとる必要があるとしましょう。

The kids are hungry, you need it fast.
子供たちは空腹です、あなたは早くそれが必要です。

You could have a shortcut that uses the Caviar app that lets you choose a restaurant, choose a meal, place the order and then text the whole family with what's for dinner and when it will arrive.
Caviarアプリを使って、レストランの選択、食事の選択、注文の実行、そして家族全員に夕食の予定と到着予定時刻のテキストを表示するショートカットを作成できます。

That's combining the power of your apps with Siri Shortcuts to make everyday tasks really easy.
それはあなたのアプリの力をSiriのショートカットと組み合わせることで日常の仕事を本当に簡単にすることです。

And of course -- [ Applause ]
そしてもちろん -  [拍手]

And of course Shortcuts work across iPhone, iPad, Apple Watch and HomePod too.
そしてもちろん、ショートカットはiPhone、iPad、Apple Watch、そしてHomePodでも使えます。

And that's our update for Siri.
それがSiriの更新です。

[ Applause ]
【拍手】

Now I'd like to invite Jeff to tell you about the latest advances in augmented reality.
それでは、拡張現実の最新の進歩についてJeffにお伝えしたいと思います。

Thank you.
ありがとうございました。

[ Applause ]
【拍手】

>> Thanks, Bill.
>>ありがとう、ビル。

I am thrilled to be here today to talk about augmented reality.
私は拡張現実について話すために今日ここにいることに興奮しています。

AR helps you visualize things that are difficult, expensive or impossible to do otherwise.
ARを使用すると、困難、高価、または不可能なことを視覚化することができます。

And since introducing AR Kit, we've seen amazing growth in applications.
そしてAR Kitを導入して以来、私たちはアプリケーションの驚くべき成長を見てきました。

One may think of AR as only for entertainment, but we've seen great applications in education, enterprise, commerce and more.
ARは娯楽のためだけのものと考えるかもしれませんが、教育、企業、商取引などで優れたアプリケーションを見てきました。

Commerce is a particularly impressive use case with Home Depot, Target and Wayfair all having tens of thousands of products available to preview in AR.
コマースは、Home Depot、Target、Wayfairで特に印象的なユースケースであり、すべてARでプレビューできる製品が数万点あります。

AR Kit hosts the USDZ file format and Quick Look together, make the world's first mass market augmented reality commerce solution.
AR KitはUSDZファイルフォーマットとQuick Lookを一緒にホストし、世界初のマスマーケット拡張現実感コマースソリューションを作ります。

In fact, Wayfair is seeing more than a threefold increase in purchasing when folks view their products in augmented reality.
実際、Wayfairは、人々が自分たちの製品を拡張現実感で見ると、購買が3倍以上に増加していると見ています。

And we love that this is a real business use case.
そしてこれが本当のビジネスユースケースであることを私たちは大好きです。

This is a great real business use case for augmented reality in commerce.
これは、商取引における拡張現実のための素晴らしい実際のビジネスユースケースです。

We'd like to continue this momentum by announcing that Apple Pay will be integrated directly with AR Quick Look this fall.
Apple Payは今秋、AR Quick Lookと直接統合されることを発表することで、この勢いを継続したいと思います。

This makes it easier for consumers to try on and buy items like these glasses, directly from augmented reality.
これにより、消費者は拡張現実から直接これらの眼鏡のような商品を試着して購入することが容易になります。

AR Kit for iOS and iPadOS are the world's largest augmented reality platform with hundreds of millions of enabled devices.
iOSおよびiPadOS用のAR Kitは、世界で最大の拡張現実プラットフォームであり、何億もの対応デバイスがあります。

And we've heard from many developers, they love to take advantage of this great opportunity but may not be sure where to start.
そして、私たちは多くの開発者から聞いた、彼らはこの素晴らしい機会を利用するのが大好きですが、どこから始めるべきか確信が持てないかもしれません。

Or 3D can be a little bit intimidating if you've never used it before.
また、3Dを使ったことがないのであれば、3Dは少し威圧的です。

Well, we've been listening and we're really excited to announce three technologies that make it much easier to develop augmented reality applications.
さて、私たちは耳を傾けてきました、そして拡張現実アプリケーションを開発することをはるかに容易にする3つの技術を発表することに本当に興奮しています。

AR Kit, RealityKit and Reality Composer together provide the frameworks and tools you need to quickly and easily develop augmented reality applications and experiences.
AR Kit、RealityKit、Reality Composerを組み合わせることで、拡張現実アプリケーションとエクスペリエンスを迅速かつ容易に開発するために必要なフレームワークとツールが提供されます。

Starting with Reality Composer, you can create compelling AR experiences even if you've never worked with 3D before.
Reality Composerから始めて、これまで3Dで作業したことがなくても魅力的なARエクスペリエンスを作成できます。

It provides an intuitive, what you see is what you get interface that integrates seamlessly with Xcode.
それは直感的にわかります、あなたが見るものはあなたがXcodeとシームレスに統合するインターフェースを得るものであるということです。

And to show you Reality Composer, I'd like to invite one of my colleagues, Shrudi, up to the stage.
そしてReality Composerを紹介するために、同僚の一人であるShrudiをステージに招待したいと思います。

[ Applause ]
【拍手】

>> Thank you, Jeff.
>>ありがとう、ジェフ。

Happy to be here.
ここにいられてうれしい。

I have this great travel app which shows some activities offered on the main island of Hawaii.
私はハワイの本島で提供されるいくつかの活動を示すこの素晴らしい旅行アプリを持っています。

If the user opts for helicopter tours, the app shows the path of the helicopter.
ユーザーがヘリコプターツアーを選択した場合、アプリはヘリコプターのパスを表示します。

How about we use AR to provide users a better sense of the actual tour?
実際のツアーの感覚をユーザーに提供するためにARを使用するのはどうですか。

I can do that by adding a button to the existing app to launch my AR experience.
既存のアプリにボタンを追加してARエクスペリエンスを起動することでそれを実現できます。

Let's see how to do that.
その方法を見てみましょう。

First, we create a button using SwiftUI.
まず、SwiftUIを使ってボタンを作成します。

Followed by adding that button to my existing view.
そのボタンを既存のビューに追加します。

Then I open an empty project file in Reality Composer and integrate it to my Xcode project by simply dragging and dropping it in Xcode.
次に、Reality Composerで空のプロジェクトファイルを開き、それをXcodeにドラッグアンドドロップするだけでXcodeプロジェクトに統合します。

To load my AR scene from this Reality Composer project file, I import RealityKit and then create a new view for AR.
このReality Composerプロジェクトファイルから自分のARシーンを読み込むために、RealityKitをインポートしてからARの新しいビューを作成します。

Oops.
おっとっと。

Sorry.
ごめんなさい。

Create a new view for AR using SwiftUI.
SwiftUIを使用してARの新しいビューを作成します。

And that's all the code you need to add an AR experience to your existing app.
これで、既存のアプリにARエクスペリエンスを追加するために必要なすべてのコードが完成しました。

Moving on to the fun part of creating my AR scene with Reality Composer.
Reality Composerを使って自分のARシーンを作成する楽しい部分に進みましょう。

I open my empty Reality project and start by loading a custom USTZ of the Hawaii model.
私は自分の空のRealityプロジェクトを開き、ハワイモデルのカスタムUSTZをロードすることから始めます。

Sweet.
甘い。

Next I'd like to mark the beginning of my helicopter tour.
次にヘリコプターツアーの始まりを迎えたいと思います。

For that I can use Reality Composer's built-in content library which offers hundreds of professional-grade 3D content to developers.
そのために、私はReality Composerの組み込みコンテンツライブラリを使用することができます。これは開発者に何百というプログレードの3Dコンテンツを提供します。

I'll use a simple sphere.
単純な球を使います。

I can change the content's look, by applying a different material to it.
別の素材を適用することで、コンテンツの外観を変えることができます。

As you can see, placing content in 3D is pretty simple and intuitive with Reality Composer.
ご覧のとおり、Reality Composerを使用すると、3Dでコンテンツを配置するのは非常に簡単で直感的です。

Let's see what else we can do here.
ここで他にできることを見てみましょう。

How about adding a cool fading effect to the scene when the scene starts.
シーンの開始時にシーンにクールなフェード効果を追加してはどうですか。

I can do that by opening the Behaviors panel and creating a custom behavior which gets triggered when the scene starts.
これは、ビヘイビアーパネルを開き、シーンの開始時にトリガーされるカスタムビヘイビアーを作成することで実現できます。

I first add an action to hide all the content in the scene.
最初にシーン内のすべてのコンテンツを非表示にするアクションを追加します。

Then the scene starts, and then add another action to make all the content appear after a certain duration.
その後、シーンが開始してから、一定の時間が経過するとすべてのコンテンツが表示されるようにするためのアクションを追加します。

How about we preview it right here?
ここでプレビューしてはどうですか。

Awesome.
驚くばかり。

Developing AR on Mac is convenient, but it poses the challenge of guessing the content scale and look when placed in real world.
Mac上でARを開発することは便利ですが、現実の世界に置かれたときにコンテンツの規模と外観を推測するという課題があります。

That's why we created Reality Composer for macOS as well as iPadOS and iOS to remove the guesswork out of development.
そのため、MacOS用、iPadOS、iOS用のReality Composerを作成して、推測から開発を除外しました。

So I'll hand this off to Jeff to see what we have so far on an iPad.
だから私はこれをJeffに渡して、これまでにiPadで何をしてきたのかを確かめる。

>> Thanks very much, Shrudi.
>>どうもありがとう、Shrudi。

So this is Reality Composer for the iPad.
だから、これはiPad用のReality Composerです。

It has the same great features that you see in the Reality Composer for the Mac.
それはあなたがMac用のリアリティ作曲家で見るのと同じ素晴らしい機能を持っています。

And we can take the seen that Shrudi handed off and finish it out with our final artwork.
そして私達はShrudiが引き渡したという見方を取り、私達の最終的なアートワークでそれを完成させることができます。

So we've had someone create with Adobe Arrow our final file or our final artwork, and we'll put it into the scene.
そこで、私たちはAdobe Arrowを使って最終的なファイルまたは最終的なアートワークを作成したので、それをシーンに入れます。

So I'm going to take the proxy art that Shrudi had.
だから私はShrudiが持っていたプロキシアートを取るつもりです。

I'm going to replace that with our new artwork.
私たちの新しいアートワークでそれを置き換えるつもりです。

Let me check to see if that's the right thing.
それが正しいことかどうか確認してみましょう。

Fantastic.
素晴らしいです。

That is our final helicopter.
それが私たちの最後のヘリコプターです。

And I also want to bring in the animation that goes with that.
それに伴うアニメーションも持ち込みたいです。

That's super easy.
とても簡単です。

If you remember, she created that behavior, so we're going to look at that behavior and all we're going to do is add an additional action.
覚えているのであれば、彼女はその振る舞いを作成したので、その振る舞いを見ていきますそして私たちがやろうとしているのは、追加のアクションを追加することだけです。

So we look for USDZ animation which is bringing in the animation that went with the file.
それで私達はファイルと一緒に行ったアニメーションを持ち込んでいるUSDZアニメーションを探します。

Fantastic.
素晴らしいです。

Looks good.
いいね。

Let's preview that.
それをプレビューしましょう。

Great.
すばらしいです。

So hide our Behaviors tab.
だから私たちの行動タブを非表示にします。

That looks like what we want.
それは私たちが欲しいもののように見えます。

Perfect.
完璧です。

Let's preview this in AR, but you can do it with the iPad.
これをARでプレビューしましょうが、iPadでもできます。

Wow.
ワオ。

Let's try that again.
もう一度試してみましょう。

Fantastic.
素晴らしいです。

That's exactly what I wanted it to look like.
それこそまさに私が望んでいたものです。

And we can also play that.
そしてそれをプレイすることもできます。

Perfect.
完璧です。

We have the animation of the helicopter touring the island.
島を巡るヘリコプターのアニメーションがあります。

That will look great in our travel application.
それは私たちの旅行アプリケーションではとてもよく似合うでしょう。

So that's Reality Composer for the iPad.
iPad用のReality Composerです。

And you're going to love how you can have the same great ease of use and seamless experience between macOS, iPadOS and iOS with Reality Composer.
そして、Reality Composerを使用して、macOS、iPadOS、およびiOSの間で同じように優れた使いやすさとシームレスなエクスペリエンスを実現する方法を気に入るはずです。

[ Applause ]
【拍手】

Now RealityKit.
今RealityKit。

RealityKit is a modern high-performance 3D engine designed from the ground up for augmented reality rendering and simulation.
RealityKitは拡張現実感レンダリングとシミュレーションのためにゼロから設計された現代の高性能3Dエンジンです。

And because it's delivered as a framework, it's very easy for all of you to take your 2D apps and extend them into 3D.
フレームワークとして提供されているため、2Dアプリケーションを3Dに拡張して拡張することは、すべての人にとって非常に簡単です。

RealityKit uses modern visibly-based rendering and materials.
RealityKitは現代の視覚ベースのレンダリングとマテリアルを使います。

It is a data-driven rendering system and a fully multi-threaded renderer that's highly optimized for Apple's GPUs.
これは、データ駆動型レンダリングシステムであり、アップルのGPU向けに最適化された完全マルチスレッドレンダラです。

And also, really importantly, we've integrated AR Kit scene understanding into RealityKit.
また、非常に重要なこととして、AR Kitのシーン理解をRealityKitに統合しました。

Which means as AR Kit leans more about the environment, it synchronizes this to your virtual scene automatically.
つまり、AR Kitは環境についてより学習しやすいので、これを仮想シーンに自動的に同期させます。

We saw RealityKit in action this morning.
今朝RealityKitが動作しているのを見ました。

Let's take a closer look.
詳しく見てみましょう。

Let's see what's really going on.
実際に何が起こっているのか見てみましょう。

The reality you see is based on things like image-based lighting, motion blur and camera effects like depth of field and camera noise that really blur the line between what is reality and what is virtual.
現実は、イメージベースのライティング、モーションブラー、被写界深度やカメラノイズなどのカメラエフェクトなど、現実と仮想の境界線をぼやけさせるものに基づいています。

And you get these features with RealityKit automatically.
そして、あなたは自動的にRealityKitでこれらの機能を手に入れます。

You access RealityKit through a new framework which is a native Swift API.
あなたはネイティブSwift APIである新しいフレームワークを通してRealityKitにアクセスします。

It takes many advantages of the key features of Swift to allow you to write clear, compact code.
Swiftの重要な機能の多くの利点を活かして、明確でコンパクトなコードを書くことができます。

Concepts Log and Rally are directly integrated.
コンセプトLogとRallyは直接統合されています。

For example, it's easy to load your AR assets and directly attach them to anchors.
たとえば、ARアセットをロードしてそれらを直接アンカーに添付するのは簡単です。

Protocol extensions provide easy access to entity property which allow you to quickly access components such as lights or shadows in this case and reduce the need for runtime checks.
プロトコル拡張はエンティティプロパティへの簡単なアクセスを提供し、この場合はライトや影などのコンポーネントにすばやくアクセスでき、実行時チェックの必要性を減らすことができます。

This also means that you're able to work with entities in a strongly-typed manner.
これはまた、あなたが強く型付けされた方法でエンティティを扱うことができるということを意味します。

Here we're applying an angular force to an entity that participates in physics.
ここでは、物理学に参加している実体に角力を加えています。

And that's all the code you need for this scene.
そして、それがこのシーンに必要なすべてのコードです。

Last but definitely not least today is a new version of our augmented reality framework AR Kit 3.
最後になりましたが、今日では拡張現実フレームワークAR Kit 3の新しいバージョンがあります。

We've taken the most capable AR platform in the world and made it even more powerful with new in-depth reverse features.
私達は世界で最も有能なARプラットフォームを採用し、新しい詳細なリバース機能でそれをさらに強力にしました。

Since introducing AR Kit, we've had many developers ask to be able to use the front and back cameras simultaneously.
AR Kitを導入して以来、フロントカメラとバックカメラを同時に使用できるようにすることを多くの開発者に求めてきました。

Well, in AR Kit 3 you can.
AR Kit 3では可能です。

So you can -- that's right, both cameras at the same time.
それであなたはできる - それは正しい、両方のカメラを同時に。

[ Applause ]
【拍手】

This allows you to use face tracking to drive your augmented reality experiences directly.
これにより、フェイストラッキングを使用して拡張現実感を直接体験できます。

And as Craig talked about this morning, properly occluding people in an AR scene is an extremely tough problem.
そして今朝Craigが話したように、ARシーンで人々を適切に隠蔽することは非常に難しい問題です。

You see it every time someone walks in front of a virtual object.
誰かが仮想オブジェクトの前を歩くたびに見えます。

To solve this, we've built an advanced machine-learning algorithm that figures out which pixels are a person, the depth of that person in the scene and uses its information to allow us to properly render the scene in the virtual objects.
これを解決するために、どのピクセルが人物であるか、シーン内のその人物の奥行きを把握し、その情報を使用して仮想オブジェクト内にシーンを適切にレンダリングできるようにする高度な機械学習アルゴリズムを構築しました。

With people occlusion, entirely new experiences like Minecraft Earth Demo you saw this morning are possible.
人々の閉塞により、今朝見たMinecraft Earth Demoのようなまったく新しい体験が可能になります。

[ Applause ]
【拍手】

Absolutely amazing.
本当にすごい。

And finally, we built a system that allows humans to interact with virtual content.
そして最後に、人間が仮想コンテンツと対話できるようにするシステムを構築しました。

AR Kit 3 is able to capture a person's motion in real time with just the single RGB camera in an iPad or iPhone.
AR Kit 3は、iPadまたはiPhoneの1台のRGBカメラで、人の動きをリアルタイムで捉えることができます。

We again use a machine learned algorithm to track the person, building a 2D stick figure and take that figure and then infer a 3D motion from them or lift it into 3D.
私達はまた機械学習されたアルゴリズムを使って人を追跡し、二次元の棒の形を​​作り、その形を取ってそれからそれらから三次元の動きを推論するかそれを三次元に持ち上げる。

Both the 2D skeleton and the 3D skeleton are available to developers.
開発者は、2Dスケルトンと3Dスケルトンの両方を利用できます。

The 3D has over 90 articulated joints and provides the same ease of use as Face Kit.
3Dは90以上の関節ジョイントを持ち、フェイスキットと同じ使いやすさを提供します。

So those are our new technologies.
それで、それらは私たちの新しい技術です。

AR Kit 3, RealityKit, and Reality Composer are tools and frameworks that make it easy for anyone, anyone, to build amazing AR experiences.
AR Kit 3、RealityKit、およびReality Composerは、誰もが誰でも簡単に素晴らしいARエクスペリエンスを構築するためのツールおよびフレームワークです。

And we'd like to do something fun today, so we have a fun new application at the conference.
そして、今日は楽しいことをしたいので、カンファレンスで楽しい新しいアプリケーションを用意しました。

You may have seen it, SwiftStrike.
あなたはそれを見たことがあるでしょう、SwiftStrike。

We're making a tabletop version of this as a developer sample available today.
私達は今日利用可能な開発者サンプルとしてこれの卓上版を作っています。

It uses RealityKit, AR Kit 3 and Reality Composer and provides a great starting point for your applications.
それはRealityKit、ARキット3とReality Composerを使い、あなたのアプリケーションのための素晴らしい出発点を提供します。

[ Music ]
[音楽]

Lots of fun.
たくさんの楽しみ。

[ Applause ]
【拍手】

Thank you.
ありがとうございました。

[ Applause ]
【拍手】

And of course Metal powers a lot of what we do in AR on our devices.
そしてもちろん、MetalはARで私たちのデバイスで行うことの多くを強化します。

And to tell you more about what's new in Metal, I'd like to welcome Jeremy to the stage.
それでは、Metalの新機能について詳しくお伝えするために、Jeremyをステージに迎え入れたいと思います。

[ Applause ]
【拍手】

>> Thank you, Jeff.
>>ありがとう、ジェフ。

So Metal is Apple's modern high-performance GPU programming API for graphics and compute.
だからMetalはグラフィックと計算のためのアップルの現代の高性能GPUプログラミングAPIです。

It's also incredibly easy to use, both for beginners and experts alike.
初心者にもエキスパートにも、非常に使いやすいです。

And it brings stunning performance increases, supporting up to 100 times more draw calls than OpenGL and enabling a whole new generation of advanced graphics performance.
そしてそれは驚くべきパフォーマンスの向上をもたらし、OpenGLよりも最大100倍多くの描画呼び出しをサポートし、そして全く新しい世代の高度なグラフィックパフォーマンスを可能にします。

This is because Metal gives your app direct control over the GPUs that are at the core of Apple's products.
これは、MetalがApple製品の中核をなすGPUを直接制御するためです。

And those GPUs now power over 1.4 billion Metal-capable system from iPhones to iPads to the all-new Mac Pro.
そしてこれらのGPUは、iPhoneからiPad、まったく新しいMac Proまで、14億以上のメタル対応システムに電力を供給しています。

In fact, all of Apple's platforms now run on Metal.
事実、Appleのすべてのプラットフォームは現在Metalで動作しています。

From our smooth user interface to the latest 3D rendering in RealityKit, to our advanced camera processing pipeline, we're using Metal everywhere.
私達の滑らかなユーザーインターフェースからRealityKitの最新3Dレンダリング、そして私達の高度なカメラ処理パイプラインまで、私達は至る所でMetalを使用しています。

And you can too.
そしてあなたもできます。

To help you do just that, this year we focused on three key areas.
そのために、今年は3つの重要分野に焦点を当てました。

We've made Metal even easier to use.
私たちはMetalをさらに使いやすくしました。

We've enabled all-new levels of high-performance GPU compute.
私たちはまったく新しいレベルの高性能GPUコンピューティングを可能にしました。

And we've enhanced Metal for our most demanding pro app developers and customers.
そして最も要求の厳しいプロアプリ開発者と顧客のためにMetalを強化しました。

First, with Metal's incredibly approachable API and GPU shading language, you can get started with our powerful suite of developer tools for GPU debugging, profiling and performance optimizing.
まず、Metalの信じられないほど親しみやすいAPIとGPUシェーディング言語を使えば、GPUのデバッグ、プロファイリング、パフォーマンスの最適化のための強力な開発者ツール一式を始めることができます。

And we've made those tools even better.
そして私達はそれらのツールをさらに良くしました。

We have added full Metal support to the iOS Simulator in Xcode.
XcodeのiOSシミュレータに完全なMetalサポートを追加しました。

[ Applause ]
【拍手】

We're glad you're excited about it.
私たちはあなたがそれに興奮してうれしいです。

We're really excited about it too.
私たちもそれにとても興奮しています。

You can now use Metal directly in the simulator and you automatically get major performance improvements when using UI Kits, Maps and all of those system frameworks built on Metal.
シミュレータでMetalを直接使用できるようになりました。UIキット、Maps、およびMetal上に構築されたすべてのシステムフレームワークを使用すると、パフォーマンスが大幅に向上します。

And this is because the iOS Simulator is now using the native Metal support built right into your Mac.
そしてこれは、iOSシミュレータが現在Macに組み込まれているネイティブのMetalサポートを使用しているためです。

We've also added an all-new Metal memory debugger.
また、まったく新しいMetalメモリデバッガも追加しました。

You can now identify exactly how much memory your app is using for Metal textures, buffers and heats and you can optimize your games and apps to use every last byte for even more advanced graphics.
これで、アプリがMetalテクスチャ、バッファ、ヒート用に使用しているメモリ量を正確に特定でき、ゲームやアプリを最適化して、さらに高度なグラフィック用にすべての最後のバイトを使用できるようになります。

Now over the past few years, Metal has grown to support the advanced features of dozens of GPUs, each with their own hardware from every major GPU vendor and across all of our platforms and OS releases.
ここ数年で、Metalは、すべての主要GPUベンダーからの独自のハードウェアと、すべてのプラットフォームおよびOSリリースにわたって、数十のGPUの高度な機能をサポートするようになりました。

And as a developer you previously had to manage all of this complexity of these different hardware feature sets yourself.
そして開発者として、以前はこれらのさまざまなハードウェア機能セットの複雑さをすべて自分で管理する必要がありました。

Well this year we've made it much simpler with just three Metal GPU families.
今年はたった3つのMetal GPUファミリで、はるかにシンプルになりました。

A Metal common GPU family, identifying the vast majority of Metal features that you can use across all of our platforms.
Metal共通GPUファミリー。当社のすべてのプラットフォームで使用できるMetal機能の大多数を識別します。

A second family for the advanced unique features of our Apple Design GPUs and our iOS, iPadOS and tvOS products.
Apple Design GPUと、iOS、iPadOS、およびtvOS製品の高度な独自機能を備えた2番目のファミリー。

And a third family for the powerful GPUs on our Mac systems.
そして私達のMacシステム上の強力なGPUのための第三のファミリーです。

And it makes it that much easier to bring your apps from iOS to macOS or the other way around.
そしてそれはあなたのアプリをiOSからmacOSへ、あるいはその逆にすることをとても簡単にします。

Now, in addition to enabling immersive games and advanced graphics, Metal also gives your app the ability to harness the GPU for compute.
これで、没入型ゲームと高度なグラフィックスを可能にすることに加えて、MetalはあなたのアプリにGPUを利用して計算する能力も与えます。

So what is GPU compute?
それではGPUは何を計算するのですか？

Well, GPUs were originally designed to process large numbers of pixels requiring the execution of complex mathematical computations in a massively parallel fashion.
さて、GPUは元々、複雑な数学的計算の実行を必要とする大量のピクセルを超並列的に処理するように設計されていました。

And it turns out we can apply that computational horsepower to a wide variety of tasks besides traditional graphics.
そして、その計算能力を従来のグラフィック以外にもさまざまなタスクに適用できることがわかりました。

So Metal provides all of the building blocks that you need for general purpose computation on the GPU.
そのため、MetalはGPUでの汎用計算に必要なすべての構成要素を提供します。

A familiar C++ based GPU programming language, compute command encoding, API and runtime, a full-feature compiler and debugger and a rich library of shaders and kernels called the Metal performance shaders.
おなじみのC ++ベースのGPUプログラミング言語、計算コマンドのエンコード、APIとランタイム、フル機能のコンパイラとデバッガ、そしてMetalパフォーマンスシェーダと呼ばれる豊富なシェーダとカーネルのライブラリ。

This MPS library provides you valuable compute functions all pre-optimized for all of those GPUs and all of those Apple systems and it's all fully integrated right into your Metal code.
このMPSライブラリは、これらすべてのGPUおよびすべてのAppleシステム用に事前に最適化された貴重な計算機能を提供し、すべてがMetalコードに完全に統合されています。

And on our Apple Design GPUs, Metal also provides advanced compute features like tile shading, enabling you to combine your compute shaders and your fragment processing into one simple, highly-efficient render pass.
また、Apple Design GPUでは、Metalはタイルシェーディングなどの高度なコンピューティング機能も提供します。これにより、コンピューティングシェーダとフラグメント処理を1つのシンプルで非常に効率的なレンダリングパスに組み合わせることができます。

And this year we're also introducing Metal indirect compute command encoding.
そして今年はMetalの間接計算コマンドのエンコーディングも紹介します。

It allows you to build your GPU compute commands right on the GPU itself, unlocking all-new algorithms for compute efficiency and freeing the CPU for other activities in your app.
それはあなたがGPU自体の上にあなたのGPU計算コマンドを構築することを可能にし、計算効率のための全く新しいアルゴリズムのロックを解除しそしてあなたのアプリの他の活動のためにCPUを解放します。

And with the Radeon Pro Vega II, the new Mac Pro is a GPU compute monster, capable of up to 56 teraflops of GPU compute all made available to you via Metal.
そして、Radeon Pro Vega IIを搭載した新しいMac Proは、最大56テラフロップのGPUコンピュートをすべてMetalで利用できるGPUコンピュートモンスターです。

Now that's a heck of a lot of flops.
これでたくさんのフロップができました。

I mean, look at them all.
つまり、それらすべてを見てください。

They barely fit on the screen.
彼らはほとんど画面に収まりません。

[ Applause ]
【拍手】

That's a lot.
それは沢山。

[ Applause ]
【拍手】

So what can you do with all of those flops of GPU compute?
それで、あなたはGPUコンピューティングのこれらのすべてのフロップで何ができるでしょうか？

Well, with Metal you can use them for advanced compute processing.
さて、Metalを使えば、それらを高度な計算処理に使うことができます。

For your videos, you can improve the quality of your photos.
ビデオの場合は、写真の品質を向上させることができます。

You can train your ML models and you can use them to accelerate interactive ray tracing.
あなたはあなたのMLモデルを訓練することができ、あなたは対話型レイトレーシングを加速するためにそれらを使うことができます。

So we have further improved Metal support for ray tracing this year, now enabling dynamic scenes by moving the bounding volume hierarchy construction from the CPU to the GPU, and added all-new optimized MPS de-noising filters to further improve image quality.
そこで、今年はレイトレーシングのMetalサポートをさらに改善し、バウンディングボリューム階層構造をCPUからGPUに移動することで動的シーンを可能にし、さらに画質をさらに向上させるためにまったく新しい最適化MPSノイズ除去フィルタを追加しました。

Now ray tracing, it uses the GPU to computationally model the physical properties of lights and surfaces and reflections and it can be so complex, people actually earn PhD's in this topic.
レイトレーシングは、GPUを使用してライトやサーフェスの物理的特性や反射を計算でモデル化します。非常に複雑になる可能性があるため、このトピックでは実際に博士号を取得しています。

So to show you how you can use Metal and GPU Compute for ray tracing, we decided to put together a pretty simple example.
そこで、レイトレーシングにMetalとGPU Computeを使用する方法を説明するために、非常に単純な例をまとめることにしました。

And I'd now like to invite Rav to the stage to give you a quick demonstration.
そして私は今すぐRavをステージに招待してあなたに素早いデモンストレーションをしたいと思います。

Rav?
ラヴ？

[ Applause ]
【拍手】

>> Thank you, Jeremy.
>>ありがとう、ジェレミー。

So we built a prototype hybrid ray tracing engine to see what we could do with Metal Compute on the powerful new Mac Pro.
そこで、強力な新しいMac ProでMetal Computeで何ができるかを確認するために、プロトタイプのハイブリッドレイトレーシングエンジンを構築しました。

Now this toy city that we built looks simple, but we're using Metal to process over 1 billion rays per second at 4K resolution.
今、私たちが建てたこのおもちゃの街はシンプルに見えますが、4Kの解像度で毎秒10億以上の光線を処理するためにMetalを使っています。

Let me walk you through what we're doing here.
ここで何をしているのかを説明しましょう。

So we start by using Metal draw commands to render the geometry and material information that we're going to use later, and then switch to using Metal Compute and the MPS ray triangle intersection APIs to do all the heavy lifting.
そのため、後で使用するジオメトリとマテリアル情報をレンダリングするためにMetal drawコマンドを使用して開始し、次にMetal ComputeとMPSレイトライアングル交差APIの使用に切り替えて、すべての面倒な作業を行います。

This includes calculating ambient light at every surface point, as you can see in this image.
この画像からわかるように、これにはすべてのサーフェスポイントでの周囲光の計算が含まれます。

But also to simulate light bouncing between objects in our scene at increasing ray depth to generate shadows, reflections and even reflections within those reflections.
しかしまた、光線の深さを増やしながらシーン内のオブジェクト間の光の跳ね返りをシミュレートして、影、反射、さらにはそれらの反射内の反射を生成することもできます。

And then we end by using the optimized MPS or optimize compute kernels in the new MPS de-noiser to produce this really high-quality image.
そして、この本当に高品質の画像を生成するために、新しいMPSノイズ除去器で最適化されたMPSまたは最適化された計算カーネルを使用することで終わります。

So traditional CPU renderers would take over a minute to generate a frame like this.
そのため、従来のCPUレンダラーは、このようなフレームを生成するのに1分以上かかります。

With Metal, we've been able to reduce this to under 30 milliseconds, which is a staggering 1,000 times faster.
Metalを使用すると、これを30ミリ秒未満に減らすことができました。これは、1,000倍も速いことです。

So pro app developers -- thank you.
だからプロアプリ開発者 - ありがとう。

We think it's pretty great too.
私達はそれもかなり素晴らしいと思います。

[ Applause ]
【拍手】

So pro app developers can now use Metal Compute to build new interactive tools to visualize these physically accurate lighting effects like these dramatic shadows that are cast by the buildings and also by that fire escape.
そのため、プロアプリの開発者は、Metal Computeを使用して、建物やその火災避難場所で発生する劇的な影のような物理的に正確な照明効果を視覚化するための新しいインタラクティブツールを構築できます。

Or if we pan over here to this roof, the realistic way that green light bounces onto this neighboring building.
あるいは、この屋根にここをパンすると、緑色の光がこの隣接する建物に当たる現実的な方法です。

That just looks great.
それはちょうどいいですね。

Thank you.
ありがとうございました。

[ Applause ]
【拍手】

Another great effect that we can simulate or model is accurate reflections, as you can see in the windshields of this bus.
このバスの風防ガラスで見ることができるように私達が模倣するか、またはモデル化できるもう一つの大きい効果は正確な反射である。

In fact, you can see the shadows moving in that windshield or in those reflections as I change the position of the sun.
実際、太陽の位置を変えると、そのフロントガラスやその反射の中で影が動くのがわかります。

So that looks great, but animating objects in a ray trace scene can be very computationally expensive because we have to update the bounding volume hierarchy that's associated with the geometry.
それで、それは素晴らしく見えます、しかし、光線追跡場面でオブジェクトをアニメートすることは非常に計算上高価であるかもしれません、なぜなら我々は幾何学に関連する境界ボリューム階層を更新しなければならないからです。

Fortunately, with Metal Compute and the MPS APIs, we're able to move all of this work onto the GPUs and achieve this great animation.
幸い、Metal ComputeとMPS APIを使用して、これらすべての作業をGPUに移行し、この素晴らしいアニメーションを実現できます。

And there go our trains.
そして私たちの電車があります。

So that was just an example of what's possible when you use Metal Compute for accelerated ray tracing on the new Mac Pro.
したがって、これは、新しいMac ProでMetal Computeを使用して光線追跡を高速化した場合に可能になることのほんの一例です。

It's a beast.
それは獣です。

Thank you.
ありがとうございました。

Back to you, Jeremy.
あなたに戻って、ジェレミー。

[ Applause ]
【拍手】

>> Thank you, Rav.
>>ありがとう、ラヴ。

So that's what we did in just a short bit of time.
だから私たちはほんの少しの間にやったことです。

But high-performance ray tracing can be even more powerful in the hands of our most expert third-party developers.
しかし、高性能レイトレーシングは、当社の最も専門的なサードパーティ開発者の手によってさらに強力になる可能性があります。

Which is why we are so excited that OTOY has announced they're using Metal Compute to build OctaneX, an all-new version of Octane Renderer, their interactive path tracing engine optimized for Metal and the Apple platforms.
そのため、OTOYが、Metal Computeを使用して、Octane Rendererのまったく新しいバージョンであるOctaneX、MetalおよびAppleプラットフォーム用に最適化されたインタラクティブパストレースエンジンを構築することを発表したことを非常に興奮しています。

And we are incredibly thrilled to be working with Maxon who's bringing their powerful GPU-accelerated renderer Redshift to the Mac with an all-new version optimized for Metal and the new Mac Pro.
そして私たちは、Metalに最適化された全く新しいバージョンと新しいMac Proを使って、彼らのパワフルなGPUアクセラレーテッドレンダラRedshiftをMacにもたらしているMaxonと協力することに非常にワクワクしています。

So with advanced Metal Compute APIs and incredibly powerful hardware, we've built Metal to power the most advanced professional content creation tools.
そのため、高度なMetal Compute APIと非常に強力なハードウェアを使用して、最先端のプロフェッショナル向けコンテンツ作成ツールを強化するためにMetalを構築しました。

And we've been working really closely with the leading app developers who have all announced that the upcoming versions of these professional content creation tools and apps will be fully optimized for Metal and the Apple platforms.
そして私たちは、これらのプロフェッショナル向けコンテンツ作成ツールとアプリケーションの今後のバージョンが、MetalとAppleのプラットフォーム用に完全に最適化されることを発表した一流のアプリ開発者と本当に緊密に協力してきました。

For instance, Serif has just announced an all-new version of Affinity Photo for Mac using Metal's graphics and Compute APIs to hypercharge their advanced photo processing engine in achieving stunning performance increases.
たとえば、Serifは、MetalのグラフィックとCompute APIを使用して、驚くほどのパフォーマンス向上を達成するために高度な写真処理エンジンを過給する、まったく新しいバージョンのAffinity Photo for Macを発表しました。

More than 10 times better performance and jaw-dropping increases of 50 times better performance using Metal with multiple GPUs on the new Mac Pro.
新しいMac Proに複数のGPUを搭載したMetalを使用すると、10倍以上のパフォーマンスと50倍のパフォーマンスの向上が見られます。

So to enable these kinds of pro apps and this kind of performance, we work really closely with our GPU hardware and software partner teams to add all-new features to Metal.
そのため、この種のプロアプリとこの種のパフォーマンスを実現するために、当社はGPUハードウェアおよびソフトウェアパートナーチームと緊密に連携して、まったく新しい機能をMetalに追加しています。

To support the new AMD Infinity Fabric link in the new Mac Pro, we added the Metal Peer Group API.
新しいMac Proで新しいAMD Infinity Fabricリンクをサポートするために、Metal Peer Group APIを追加しました。

So what does this do?
それで、これは何をしますか？

Well, previously sharing workloads across multiple GPUs would require moving large amounts of data in a round trip across the PCI bus.
さて、以前は複数のGPUでワークロードを共有していたため、大量のデータをPCIバスを介して1往復で移動する必要がありました。

But with the Metal Peer Group API, apps can use multiple GPUs much more efficiently, directly sharing data across the Infinity Fabric link and without taking that long and scenic route through system memory.
しかし、Metal Peer Group APIを使用すると、アプリケーションは複数のGPUをはるかに効率的に使用して、Infinity Fabricリンクを介してデータを直接共有することができます。

Now finally, you've seen how you can use Metal Compute and the new Mac Pro to process a whole lot more pixels.
最後に、Metal Computeと新しいMac Proを使用して、はるかに多くのピクセルを処理する方法を説明しました。

But we also want you to produce even more beautiful pixels.
しかし私達はまたあなたにさらにもっと美しいピクセルを作り出してほしいです。

So we've introduced the gorgeous new Pro Display XDR with all-new HDR software support in macOS.
そこで私たちは、macOSでまったく新しいHDRソフトウェアをサポートしたゴージャスな新しいPro Display XDRを紹介しました。

You can now use the AV Foundation APIs to decode HDR videos or you can render native HDR content directly with Metal.
AV Foundation APIを使用してHDRビデオをデコードすることも、ネイティブのHDRコンテンツをMetalで直接レンダリングすることもできます。

You can manage the HDR display tone mapping yourself or you can let the window system and our advanced display system software handle it all for you.
あなたはHDRディスプレイトーンマッピングをあなた自身で管理することができますか、またはあなたはウィンドウシステムと私達の高度なディスプレイシステムソフトウェアがあなたのためにそれをすべて扱うようにすることができます。

And with these same APIs, you can also access a far greater range of brightness levels on many of our existing Mac displays as well.
また、これらの同じAPIを使用して、既存のMacディスプレイの多くではるかに広い範囲の明るさレベルにもアクセスできます。

So that's our Metal update for today.
これが今日のMetalアップデートです。

It's even easier to use Metal across all of our platforms with Metal in the iOS Simulator and simplified GPU families.
iOSシミュレータのMetalと単純化されたGPUファミリを使用すると、すべてのプラットフォームでMetalを使用することがさらに簡単になります。

We have all-new features and powerful hardware to unleash all-new levels of GPU compute performance.
私たちはまったく新しい機能と強力なハードウェアを使って、まったく新しいレベルのGPUコンピューティング性能を発揮します。

And we built Metal to be the best GPU programming API to drive modern professional content creation tools and apps.
そして、私たちはMetalを、最新のプロフェッショナルコンテンツ作成ツールとアプリケーションを動かすための最高のGPUプログラミングAPIであるように構築しました。

So thank you very much.
どうもありがとうございました。

I'll hand it back to Sebastien now.
私は今それをSebastienに渡します。

Thank you.
ありがとうございました。

[ Applause ]
【拍手】

>> Thank you, Jeremy.
>>ありがとう、ジェレミー。

Don't you love Metal?
あなたはメタルが好きではありませんか？

Don't you love the power of Metal?
あなたはメタルの力が好きではありませんか？

Really, really amazing.
本当にすごいね。

Now what you've seen this afternoon is a huge amount of new technology that's new for all of you as developers.
今日の午後に見たのは、開発者としてあなた全員にとって新しい大量の新技術です。

And what we've shown covering developer tools, the Apple platforms and core technologies is just some of the highlights.
開発者向けツール、アップルのプラットフォーム、そしてコアテクノロジーをカバーしているのは、ほんの一部のハイライトです。

We actually have so much more to show you this week.
私たちは実際に今週あなたに見せるためにそんなにたくさんあります。

And so ahead of us are 109 different sessions.
そして私たちの前には109の異なるセッションがあります。

And it turns out that that wasn't enough to cover everything.
そして、それはすべてを網羅するのに十分ではなかったことがわかりました。

So this year we added an additional 27 video-only sessions.
そこで今年はさらに27回のビデオのみのセッションを追加しました。

And when you want to dive even deeper, you could sit down with some of the over 1,000 Apple engineers that are here at WWDC in 229 different lab sessions throughout the week.
さらに深く掘り下げたいときは、週に229回の異なるラボセッションで、ここにいる1000人以上のアップルエンジニアと一緒に座ることができます。

So get out there and prepare to have your minds blown.
だからそこに出て、あなたの心を爆破させる準備をしてください。

It's going to be a great week.
それは素晴らしい週になるだろう。

Thank you.
ありがとうございました。

[ Applause ]
【拍手】

